# Phase 18.1-02: 3-Point Alignment Algorithm

**Phase**: 18.1 - Surface Calibration
**Requirement**: REQ-PROJ-02
**Priority**: P0
**Est. Effort**: 1.5 days
**Depends on**: 18.1-01 (Calibration Types)

## Goal

Implement the 3-point alignment algorithm for planar surface calibration, adapted from Compify's camera_align.py.

## Background

From Compify's approach:
1. Build orthogonal coordinate systems from 3 points
2. Compute scale from average distances
3. Compute rotation from orthonormal bases
4. Apply translation

This assumes a **planar target surface** (single flat plane).

## Algorithm Reference

```python
def three_point_alignment(
    track_points: List[Vector],  # 3 points in projector space
    scene_points: List[Vector]   # 3 points in world space
) -> Matrix:
    """
    Compute transform from 3 track points to 3 scene points.

    Steps:
    1. Build orthonormal basis from track points (projector space)
    2. Build orthonormal basis from scene points (world space)
    3. Compute rotation: R = scene_basis @ track_basis.T
    4. Compute scale: s = mean_distance(scene) / mean_distance(track)
    5. Compute translation: t = scene_center - s * R @ track_center
    6. Return 4x4 transform matrix
    """
```

## Tasks

### 1. Create Alignment Module (`lib/cinematic/projection/physical/calibration/alignment.py`)

```python
import math
from mathutils import Vector, Matrix
from typing import List, Tuple, Optional
from dataclasses import dataclass

@dataclass
class AlignmentResult:
    """Result of alignment computation."""
    transform: Matrix           # 4x4 transform matrix
    scale: float                # Computed scale factor
    rotation: Quaternion        # Computed rotation
    translation: Vector         # Computed translation
    error: float                # RMS alignment error in world units
    error_px: float             # RMS alignment error in projector pixels


def build_orthonormal_basis(p1: Vector, p2: Vector, p3: Vector) -> Tuple[Vector, Vector, Vector, Vector]:
    """
    Build orthonormal basis from 3 points.

    Returns:
        (origin, x_axis, y_axis, z_axis) - Orthonormal basis vectors
    """
    # Origin at first point
    origin = p1

    # X-axis: p1 -> p2 direction
    x_axis = (p2 - p1).normalized()

    # Y-axis: perpendicular to x, in plane of p1, p2, p3
    v = p3 - p1
    y_temp = v - v.dot(x_axis) * x_axis
    y_axis = y_temp.normalized()

    # Z-axis: perpendicular to x and y
    z_axis = x_axis.cross(y_axis).normalized()

    return origin, x_axis, y_axis, z_axis


def compute_alignment_transform(
    projector_points: List[Vector],
    world_points: List[Vector]
) -> AlignmentResult:
    """
    Compute transform from projector space to world space using 3-point alignment.

    Args:
        projector_points: 3 points in projector UV space (0-1 range)
        world_points: 3 corresponding points in world space (meters)

    Returns:
        AlignmentResult with transform matrix and error metrics
    """
    if len(projector_points) != 3 or len(world_points) != 3:
        raise ValueError("Exactly 3 points required for 3-point alignment")

    # Build orthonormal bases
    proj_origin, proj_x, proj_y, proj_z = build_orthonormal_basis(*projector_points)
    world_origin, world_x, world_y, world_z = build_orthonormal_basis(*world_points)

    # Build rotation matrices from bases
    proj_basis = Matrix.Identity(3)
    proj_basis[0] = proj_x
    proj_basis[1] = proj_y
    proj_basis[2] = proj_z

    world_basis = Matrix.Identity(3)
    world_basis[0] = world_x
    world_basis[1] = world_y
    world_basis[2] = world_z

    # Rotation: world_basis @ proj_basis.T
    rotation = world_basis @ proj_basis.transposed()

    # Scale from average distances
    proj_distances = [
        (projector_points[1] - projector_points[0]).length,
        (projector_points[2] - projector_points[0]).length,
        (projector_points[2] - projector_points[1]).length,
    ]
    world_distances = [
        (world_points[1] - world_points[0]).length,
        (world_points[2] - world_points[0]).length,
        (world_points[2] - world_points[1]).length,
    ]
    scale = sum(world_distances) / sum(proj_distances)

    # Translation
    translation = world_origin - scale * (rotation @ proj_origin)

    # Build 4x4 transform
    transform = Matrix.Translation(translation) @ scale * rotation.to_4x4()

    # Compute error
    error = compute_alignment_error(projector_points, world_points, transform)

    return AlignmentResult(
        transform=transform,
        scale=scale,
        rotation=rotation.to_quaternion(),
        translation=translation,
        error=error,
        error_px=error * 1000  # Approximate pixels (will be refined)
    )


def compute_alignment_error(
    projector_points: List[Vector],
    world_points: List[Vector],
    transform: Matrix
) -> float:
    """Compute RMS alignment error."""
    errors = []
    for proj_pt, world_pt in zip(projector_points, world_points):
        # Transform projector point to world space (add Z=0 for 2D points)
        proj_pt_3d = Vector((proj_pt.x, proj_pt.y, 0))
        transformed = transform @ proj_pt_3d
        error = (transformed - world_pt).length
        errors.append(error)
    return math.sqrt(sum(e**2 for e in errors) / len(errors))
```

### 2. Create Keystone Correction (`lib/cinematic/projection/physical/calibration/keystone.py`)

```python
def compute_keystone_correction(
    projector_profile: ProjectorProfile,
    surface_normal: Vector,
    projector_direction: Vector
) -> Tuple[float, float]:
    """
    Compute keystone correction values from surface/projector alignment.

    Returns:
        (horizontal_keystone, vertical_keystone) in degrees
    """
    # Angle between projector direction and surface normal
    dot = projector_direction.dot(surface_normal)
    angle = math.acos(dot)

    # Decompose into horizontal and vertical components
    # ... implementation
    return h_keystone, v_keystone


def apply_keystone_to_camera(
    camera: bpy.types.Object,
    h_keystone: float,
    v_keystone: float
) -> None:
    """Apply keystone correction via lens shift."""
    # Convert keystone angle to shift percentage
    # lens_shift = tan(keystone_angle) * some_factor
    pass
```

### 3. Create Surface Transform Calculator (`lib/cinematic/projection/physical/calibration/surface_transform.py`)

```python
@dataclass
class SurfaceTransform:
    """Complete transform from projector to surface."""
    projector_to_world: Matrix    # Full transform
    surface_normal: Vector         # Normal of projection surface
    surface_bounds: Tuple[Vector, Vector]  # (min, max) in world space
    projection_center: Vector      # Center of projection area


def calculate_surface_transform(
    projector: bpy.types.Object,
    calibration: SurfaceCalibration
) -> SurfaceTransform:
    """
    Calculate complete surface transform from calibration data.

    This is the main entry point for projector-to-surface mapping.
    """
    if calibration.calibration_type == CalibrationType.THREE_POINT:
        result = compute_alignment_transform(
            [p.projector_uv for p in calibration.points],
            [Vector(p.world_position) for p in calibration.points]
        )
        # ... build SurfaceTransform
    elif calibration.calibration_type == CalibrationType.FOUR_POINT_DLT:
        # Will be implemented in separate function
        pass
```

## Deliverables

```
lib/cinematic/projection/physical/calibration/
├── alignment.py          # 3-point alignment algorithm
├── keystone.py           # Keystone correction utilities
└── surface_transform.py  # Surface transform calculator
```

## Tests

- `test_alignment.py`: Alignment algorithm tests with known transforms
- `test_keystone.py`: Keystone correction tests
- Edge cases: collinear points, degenerate configurations

## Acceptance Criteria

- [ ] 3-point alignment produces correct transform for known test cases
- [ ] Alignment error < 1mm for synthetic test data
- [ ] Keystone correction calculates correct values
- [ ] Surface transform integrates with projector profile
- [ ] 20+ unit tests passing
