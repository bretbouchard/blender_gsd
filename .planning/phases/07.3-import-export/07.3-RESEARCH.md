# Phase 7.3: External Import/Export - Research

**Researched:** 2026-02-19
**Domain:** External tracking data import/export for match-move workflows
**Confidence:** HIGH

## Summary

This phase extends the existing `lib/cinematic/tracking/import_export.py` module to add comprehensive support for professional match-move software formats. The foundation is already laid with parsers for FBX, Alembic, BVH, Nuke .chan, and JSON formats. The phase focuses on completing Collada (.dae) import, adding C3D motion capture support, and implementing 3DEqualizer and SynthEyes export integration.

**Primary recommendation:** Extend existing import_export.py with ColladaParser, C3DParser, and vendor-specific export helpers. Leverage Blender's native importers where possible, fall back to custom parsers for advanced features.

## Standard Stack

### Core
| Library | Version | Purpose | Why Standard |
|---------|---------|---------|--------------|
| `bpy.ops.import_scene.fbx` | Built-in | FBX camera import | Blender native, handles coordinate conversion |
| `bpy.ops.wm.alembic_import` | Built-in | Alembic camera import | Native support for animated cameras |
| `bpy.ops.wm.collada_import` | Built-in | Collada .dae import | Native support with animation binding |
| `bpy.ops.import_anim.bvh` | Built-in | BVH mocap import | Creates armature from hierarchy |
| `struct` | stdlib | Binary C3D parsing | No external dependencies needed |

### Supporting
| Library | Version | Purpose | When to Use |
|---------|---------|---------|-------------|
| `json` | stdlib | Custom JSON format | Simple interchange |
| `re` | stdlib | Text file parsing | Nuke .chan, BVH hierarchy |
| `math` | stdlib | Quaternion/euler conversion | All rotation handling |

### Existing Implementation (Phase 7.0)
| Module | Status | Coverage |
|--------|--------|----------|
| `FBXParser` | Implemented | Blender import + fallback |
| `AlembicParser` | Implemented | Blender import + fallback |
| `BVHParser` | Implemented | Text parsing with hierarchy |
| `NukeChanParser` | Implemented | Frame-by-frame text parsing |
| `JSONCameraParser` | Implemented | Custom JSON format |
| `ImportedCamera` | Implemented | Dataclass for all formats |
| `TrackingImporter` | Implemented | Unified import interface |
| `TrackingExporter` | Implemented | Nuke .chan and JSON export |

### Missing Implementations (Phase 7.3 Scope)
| Parser | Priority | Effort |
|--------|----------|--------|
| `ColladaParser` | P1 | 1 day |
| `C3DParser` | P2 | 1 day |
| `TDEExportHelper` | P1 | 0.5 day |
| `SynthEyesExportHelper` | P1 | 0.5 day |

## Architecture Patterns

### Recommended Project Structure
```
lib/cinematic/tracking/
├── import_export.py          # Main module (extend existing)
├── formats/                  # NEW: Format-specific parsers
│   ├── __init__.py
│   ├── collada.py           # Collada .dae parser
│   ├── c3d.py               # C3D binary parser
│   └── vendor/              # Vendor-specific exports
│       ├── __init__.py
│       ├── tdequalizer.py   # 3DEqualizer export
│       └── syntheyes.py     # SynthEyes export
└── types.py                  # Existing data types
```

### Pattern 1: Unified Import Interface
**What:** All formats use `ImportedCamera` dataclass as intermediate representation
**When to use:** All new parsers must follow this pattern
**Example:**
```python
# Source: lib/cinematic/tracking/import_export.py
class ColladaParser:
    @staticmethod
    def parse(filepath: str, coordinate_system: str = "y_up") -> ImportedCamera:
        """
        Parse Collada file and extract camera animation.

        Args:
            filepath: Path to .dae file
            coordinate_system: Source coordinate system

        Returns:
            ImportedCamera with animation data
        """
        camera = ImportedCamera(
            name=Path(filepath).stem,
            source_file=filepath,
            source_format="collada",
        )

        if HAS_BLENDER:
            return ColladaParser._parse_via_blender(filepath, camera)

        return ColladaParser._parse_fallback(filepath, camera)
```

### Pattern 2: Blender-Native Import with Fallback
**What:** Use Blender's built-in importers when available, custom parsing for testing
**When to use:** All parsers that have Blender support
**Example:**
```python
# Source: lib/cinematic/tracking/import_export.py (existing)
def _parse_via_blender(self, filepath: str, camera: ImportedCamera) -> ImportedCamera:
    """Parse using Blender's native importer."""
    # Import the file
    bpy.ops.wm.collada_import(
        filepath=filepath,
        import_units=True,
        bind_animation=True,
    )

    # Find imported camera
    for obj in bpy.context.scene.objects:
        if obj.type == 'CAMERA':
            camera.name = obj.name
            # Extract animation from f-curves
            if obj.animation_data and obj.animation_data.action:
                for fcurve in obj.animation_data.action.fcurves:
                    # Extract position/rotation keyframes
                    pass
            return obj
    return camera
```

### Pattern 3: Coordinate System Conversion
**What:** Standard matrix for Y-up to Z-up conversion
**When to use:** All imports from Maya/Nuke/Houdini coordinate systems
**Example:**
```python
# Y-up to Z-up transformation matrix
COORDINATE_CONVERT = {
    "y_up_to_z_up": lambda x, y, z: (x, z, -y),
    "z_up_to_y_up": lambda x, y, z: (x, -z, y),
}

# Rotation conversion (euler)
ROTATION_CONVERT = {
    "y_up_to_z_up": lambda rx, ry, rz: (rx, rz, -ry),
    "z_up_to_y_up": lambda rx, ry, rz: (rx, -rz, ry),
}

# Existing in import_export.py
COORDINATE_SYSTEMS = {
    "blender": {"up": "Z", "forward": "-Y", "handedness": "right"},
    "maya": {"up": "Y", "forward": "Z", "handedness": "right"},
    "nuke": {"up": "Y", "forward": "-Z", "handedness": "right"},
    "houdini": {"up": "Y", "forward": "Z", "handedness": "right"},
    "3ds_max": {"up": "Z", "forward": "Y", "handedness": "right"},
    "c4d": {"up": "Y", "forward": "Z", "handedness": "left"},
    "unreal": {"up": "Z", "forward": "Y", "handedness": "left"},
}
```

### Anti-Patterns to Avoid
- **Don't duplicate Blender's native importers** - Use bpy.ops for FBX, Alembic, Collada
- **Don't ignore animation data** - Always check obj.animation_data.action for imported cameras
- **Don't skip coordinate conversion** - Y-up to Z-up is critical for correct alignment
- **Don't create cameras without keyframes** - Import should produce animated Blender camera

## Don't Hand-Roll

Problems that look simple but have existing solutions:

| Problem | Don't Build | Use Instead | Why |
|---------|-------------|-------------|-----|
| FBX import | Custom FBX parser | `bpy.ops.import_scene.fbx` | Handles binary/ASCII, coordinate systems |
| Alembic import | Custom ABC parser | `bpy.ops.wm.alembic_import` | Native support for animated cameras |
| Collada import | Custom DAE parser | `bpy.ops.wm.collada_import` | XML complexity, animation binding |
| BVH import | Custom hierarchy parser | `bpy.ops.import_anim.bvh` | Handles skeleton + motion |
| Quaternion conversion | Manual math | `math` module + existing `_euler_to_quaternion` | Edge cases in gimbal lock |
| FOV to focal length | Simple formula | Existing in camera_match.py | Tested formula with sensor width |

**Key insight:** Blender's native importers handle coordinate conversion automatically. Custom parsers only needed for formats Blender doesn't support (C3D, vendor-specific exports).

## Common Pitfalls

### Pitfall 1: Coordinate System Mismatch
**What goes wrong:** Imported camera faces wrong direction or has inverted axes
**Why it happens:** Different software uses different up/forward axes
**How to avoid:** Always specify and convert coordinate system in parser
**Warning signs:** Camera points away from subject, rotation values seem inverted

### Pitfall 2: Frame Range Misalignment
**What goes wrong:** Animation starts at wrong frame or has gaps
**Why it happens:** Some formats use 0-based frames, others 1-based
**How to avoid:** Use `frame_offset` parameter to shift frame numbers
**Warning signs:** First/last frame missing, animation out of sync with footage

### Pitfall 3: Scale Factor Errors
**What goes wrong:** Camera moves too fast/slow, tracking points at wrong scale
**Why it happens:** FBX often uses centimeters, Blender uses meters
**How to avoid:** Apply `scale_factor` (typically 0.01 for cm to m)
**Warning signs:** Camera orbit is microscopic or enormous

### Pitfall 4: Missing Animation Data
**What goes wrong:** Camera imported but has no keyframes
**Why it happens:** Importer didn't bind animation or animation on wrong object
**How to avoid:** Check `animation_data.action` and iterate through f-curves
**Warning signs:** Static camera, no motion blur in preview

### Pitfall 5: Typo in PARSERS Dictionary
**What goes wrong:** Import fails with "unsupported format" for valid extension
**Why it happens:** Line 507 has typo: `FBHParser` instead of `FBXParser`
**How to avoid:** Fix existing bug in import_export.py line 507
**Warning signs:** `.fbx` files not recognized

## Code Examples

### Collada Import (via Blender)
```python
# Source: Blender API documentation
class ColladaParser:
    @staticmethod
    def parse(filepath: str, coordinate_system: str = "y_up") -> ImportedCamera:
        camera = ImportedCamera(
            name=Path(filepath).stem,
            source_file=filepath,
            source_format="collada",
        )

        if HAS_BLENDER:
            return ColladaParser._parse_via_blender(filepath, camera)

        return camera

    @staticmethod
    def _parse_via_blender(filepath: str, camera: ImportedCamera) -> ImportedCamera:
        """Import Collada using Blender's native importer."""
        # Store current selection
        selected_before = set(bpy.context.selected_objects)

        # Import Collada with animation binding
        bpy.ops.wm.collada_import(
            filepath=filepath,
            import_units=True,
            custom_normals=True,
            auto_connect=True,
            find_chains=True,
            fix_orientation=True,
            bind_animation=True,  # Critical for camera animation
        )

        # Find newly imported cameras
        for obj in bpy.context.scene.objects:
            if obj.type == 'CAMERA' and obj not in selected_before:
                camera.name = obj.name

                # Extract animation data
                if obj.animation_data and obj.animation_data.action:
                    action = obj.animation_data.action

                    for fcurve in action.fcurves:
                        data_path = fcurve.data_path

                        for keyframe in fcurve.keyframe_points:
                            frame = int(keyframe.co.x)
                            value = keyframe.co.y

                            if data_path == "location":
                                idx = fcurve.array_index
                                pos = list(camera.positions.get(frame, (0, 0, 0)))
                                pos[idx] = value
                                camera.positions[frame] = tuple(pos)

                            elif data_path == "rotation_euler":
                                idx = fcurve.array_index
                                rot = list(camera.rotations_euler.get(frame, (0, 0, 0)))
                                rot[idx] = math.degrees(value)  # Radians to degrees
                                camera.rotations_euler[frame] = tuple(rot)

                if camera.positions:
                    camera.frame_start = min(camera.positions.keys())
                    camera.frame_end = max(camera.positions.keys())

                return camera

        return camera
```

### C3D Binary Parsing
```python
# Source: C3D specification (c3d.org)
class C3DParser:
    """
    Parser for C3D motion capture marker data.

    C3D is a binary format storing 3D marker positions.
    Used by Vicon, OptiTrack, Qualisys systems.
    """

    @staticmethod
    def parse(filepath: str) -> ImportedCamera:
        """Parse C3D file and extract marker data."""
        camera = ImportedCamera(
            name=Path(filepath).stem,
            source_file=filepath,
            source_format="c3d",
        )

        with open(filepath, 'rb') as f:
            # Read header
            header = C3DParser._read_header(f)

            # Read parameter section
            params = C3DParser._read_parameters(f, header)

            # Read point data
            points = C3DParser._read_points(f, header, params)

            # Convert to camera positions (using first marker as reference)
            camera.frame_start = 1
            camera.frame_end = header['frame_count']

            for i, frame_points in enumerate(points):
                frame = i + 1
                if frame_points:
                    # Use first marker position
                    marker = frame_points[0]
                    camera.positions[frame] = (
                        marker['x'] * params.get('scale', 1.0),
                        marker['y'] * params.get('scale', 1.0),
                        marker['z'] * params.get('scale', 1.0),
                    )

        return camera

    @staticmethod
    def _read_header(f) -> Dict[str, Any]:
        """Read C3D header block (first 256 bytes)."""
        # First byte contains parameter start block
        param_start = struct.unpack('B', f.read(1))[0]

        # Skip to relevant header fields
        f.seek(0)

        header = {
            'param_start': param_start,
            'marker_count': struct.unpack('<H', f.read(2))[0],
            'analog_count': struct.unpack('<H', f.read(2))[0],
            'first_frame': struct.unpack('<H', f.read(2))[0],
            'last_frame': struct.unpack('<H', f.read(2))[0],
        }

        # Calculate frame count
        header['frame_count'] = header['last_frame'] - header['first_frame'] + 1

        return header

    @staticmethod
    def _read_parameters(f, header: Dict) -> Dict[str, Any]:
        """Read C3D parameter section."""
        f.seek(header['param_start'] * 256)

        params = {
            'scale': 1.0,
            'units': 'mm',
        }

        # Parameter parsing is complex - simplified for research
        # Full implementation would parse groups and parameters

        return params

    @staticmethod
    def _read_points(f, header: Dict, params: Dict) -> List[List[Dict]]:
        """Read 3D point data for all frames."""
        # Data starts at block 3 (byte 768)
        f.seek(768)

        frames = []
        marker_count = header['marker_count']
        frame_count = header['frame_count']

        for _ in range(frame_count):
            frame_points = []

            for _ in range(marker_count):
                # Each point: x, y, z, residual (floats or integers)
                # Format depends on scale factor sign
                x, y, z = struct.unpack('<fff', f.read(12))
                residual = struct.unpack('<f', f.read(4))[0]

                frame_points.append({
                    'x': x,
                    'y': y,
                    'z': z,
                    'residual': residual,
                })

            frames.append(frame_points)

        return frames
```

### 3DEqualizer Export Helper
```python
# Source: 3DEqualizer documentation
class TDEExportHelper:
    """
    Export helper for 3DEqualizer integration.

    Generates Python script that 3DE can execute to create
    a Blender camera from tracking data.
    """

    @staticmethod
    def generate_blender_script(
        camera: ImportedCamera,
        point_cloud: Optional[List[Tuple[float, float, float]]] = None,
    ) -> str:
        """Generate Python script for 3DE to export to Blender."""
        script = '''# 3DEqualizer to Blender export
# Generated by Blender GSD Tracking System

import bpy

def create_tracked_camera():
    """Create camera from 3DE tracking data."""

    # Create camera object
    cam_data = bpy.data.cameras.new(name="3de_camera_data")
    cam_obj = bpy.data.objects.new("3de_camera", cam_data)
    bpy.context.collection.objects.link(cam_obj)

    # Set camera animation
'''

        # Add keyframe data
        for frame in sorted(camera.positions.keys()):
            pos = camera.positions[frame]
            rot = camera.rotations_euler.get(frame, (0, 0, 0))

            script += f'''
    # Frame {frame}
    cam_obj.location = {pos}
    cam_obj.rotation_euler = [math.radians(r) for r in {rot}]
    cam_obj.keyframe_insert(data_path="location", frame={frame})
    cam_obj.keyframe_insert(data_path="rotation_euler", frame={frame})
'''

        # Add point cloud if provided
        if point_cloud:
            script += '''
    # Create point cloud from tracking points
    mesh = bpy.data.meshes.new("tracking_points")
    obj = bpy.data.objects.new("tracking_points", mesh)
    bpy.context.collection.objects.link(obj)

    from bpy_extras.mesh_utils import mesh_from_points
    points = [
'''
            for point in point_cloud:
                script += f'        {point},\n'

            script += '''    ]
    mesh_from_points(mesh, points)
'''

        script += '''
create_tracked_camera()
print("3DE camera imported successfully!")
'''
        return script
```

### Nuke .chan Export (Existing)
```python
# Source: lib/cinematic/tracking/import_export.py
def export_nuke_chan(
    self,
    solve: Solve,
    filepath: str,
    coordinate_system: str = "nuke",
) -> bool:
    """
    Export solve to Nuke .chan format.

    Args:
        solve: Solve to export
        filepath: Output file path
        coordinate_system: Target coordinate system

    Returns:
        True if successful
    """
    try:
        with open(filepath, "w") as f:
            f.write("# Nuke camera channel export\n")
            f.write(f"# Frame range: {solve.results[0].frame} - {solve.results[-1].frame}\n")

            for result in solve.results:
                # Convert position
                pos = self._position_to_target(
                    result.position,
                    "blender",
                    coordinate_system,
                )

                # Convert rotation (euler from quaternion)
                euler = self._quaternion_to_euler(result.rotation)
                rot = self._rotation_to_target(euler, "blender", coordinate_system)

                # Frame, tx, ty, tz, rx, ry, rz, focal
                line = f"{result.frame} {pos[0]:.6f} {pos[1]:.6f} {pos[2]:.6f} "
                line += f"{rot[0]:.6f} {rot[1]:.6f} {rot[2]:.6f} "
                line += f"{result.focal_length:.4f}\n"

                f.write(line)

        return True

    except Exception:
        return False
```

## State of the Art

| Old Approach | Current Approach | When Changed | Impact |
|--------------|------------------|--------------|--------|
| Custom FBX parser | Use bpy.ops.import_scene.fbx | Phase 7.0 | Leverage native support |
| Text-based BVH | bpy.ops.import_anim.bvh + text parsing | Phase 7.0 | Both paths available |
| Single coordinate system | Per-format coordinate config | Phase 7.0 | Flexible import |
| Export only Nuke .chan | Export to Nuke + JSON + vendor scripts | Phase 7.3 | Multi-target export |

**Deprecated/outdated:**
- `FBHParser` typo in PARSERS dict: Should be `FBXParser` (line 507)

## Open Questions

### 1. C3D Binary Format Variants
- **What we know:** C3D has Intel vs. DEC byte ordering variants
- **What's unclear:** Which variant is most common in production
- **Recommendation:** Implement Intel format first (most common), add DEC detection

### 2. 3DEqualizer Direct Export
- **What we know:** 3DE can export FBX, Python scripts
- **What's unclear:** Whether to generate import scripts or just use FBX
- **Recommendation:** FBX is sufficient for camera data, Python scripts for advanced features (point cloud, distortion)

### 3. SynthEyes Integration Depth
- **What we know:** SynthEyes exports FBX, Collada, direct scripts
- **What's unclear:** Whether to support SynthEyes-specific features (lens distortion, zoom)
- **Recommendation:** FBX covers 90% of use cases, document SynthEyes FBX export settings

### 4. USDZ Scan Import
- **What we know:** Apple AR format for LiDAR scans
- **What's unclear:** Blender USD support for camera/mesh from USDZ
- **Recommendation:** Use bpy.ops.wm.usd_import (Blender 3.0+), defer to Phase 7.5

## Sources

### Primary (HIGH confidence)
- `/Users/bretbouchard/apps/blender_gsd/lib/cinematic/tracking/import_export.py` - Existing implementation patterns
- `/Users/bretbouchard/apps/blender_gsd/lib/cinematic/tracking/types.py` - Data type definitions
- `/Users/bretbouchard/apps/blender_gsd/.planning/REQUIREMENTS_TRACKING.md` - Format requirements

### Secondary (MEDIUM confidence)
- Web research on coordinate system transformation (Y-up to Z-up matrix)
- Web research on BVH file format structure (hierarchy + motion sections)
- Web research on C3D binary format (header + data blocks)
- Web research on 3DEqualizer/SynthEyes export formats

### Tertiary (LOW confidence)
- Web search tool returned limited results for specific format specifications
- Recommend verifying C3D parsing with actual test files

## Metadata

**Confidence breakdown:**
- Standard stack: HIGH - Existing code provides proven patterns
- Architecture: HIGH - Module structure already established
- Pitfalls: HIGH - Based on existing implementation bugs and VFX industry knowledge

**Research date:** 2026-02-19
**Valid until:** 2026-03-19 (30 days - stable APIs)

## Action Items for Planning

1. **Fix existing bug:** Line 507 in import_export.py has `FBHParser` typo - change to `FBXParser`
2. **Implement ColladaParser:** Add to PARSERS dict, use Blender native import
3. **Implement C3DParser:** Add binary parsing for marker data (Phase 7.5, P2)
4. **Add vendor export helpers:** TDEExportHelper, SynthEyesExportHelper for script generation
5. **Extend TrackingExporter:** Add FBX export using bpy.ops.export_scene.fbx
6. **Add scan format support:** PLY, LAS, E57 parsers (Phase 7.5, REQ-TRACK-SCAN)
