# Phase 7.4 Research: Compositing & Shot Integration

**Phase**: 7.4 - Compositing & Shot Integration
**Research Date**: 2026-02-19
**Requirements**: REQ-TRACK-COMPOSITE, REQ-TRACK-SHOT

---

## Executive Summary

This research document covers the technical knowledge needed to plan Phase 7.4, which integrates motion tracking with compositing and shot assembly. The key challenge is creating compositor nodes automatically from tracking data and enabling seamless workflows where a single YAML configuration produces a tracked composite shot.

---

## 1. Blender Compositor Node API (bpy.types.CompositorNode*)

### 1.1 Core Compositor Setup Pattern

The existing codebase has established patterns in `lib/cinematic/lens_fx.py` and `lib/cinematic/color.py`:

```python
# Enable compositor
scene = bpy.context.scene
scene.use_nodes = True
tree = scene.node_tree

# Get/create Render Layers
render_layers = tree.nodes.get('Render Layers')
if not render_layers:
    render_layers = tree.nodes.new('CompositorNodeRLayers')
    render_layers.name = 'Render Layers'

# Get/create Composite output
composite = tree.nodes.get('Composite')
if not composite:
    composite = tree.nodes.new('CompositorNodeComposite')
    composite.name = 'Composite'

# Link nodes
tree.links.new(output_socket, input_socket)
```

### 1.2 Relevant Compositor Node Types for Tracking

| Node Type | Class Name | Use Case |
|-----------|------------|----------|
| **Image Input** | `CompositorNodeImage` | Load background footage |
| **Transform** | `CompositorNodeTransform` | Basic 2D transforms |
| **Translate** | `CompositorNodeTranslate` | Pixel offset for stabilization |
| **Rotate** | `CompositorNodeRotate` | Rotation stabilization |
| **Scale** | `CompositorNodeScale` | Scale adjustments |
| **Corner Pin** | `CompositorNodeCornerPin` | Planar tracking insertion |
| **Lens Distortion** | `CompositorNodeLensdist` | Apply/remove lens distortion |
| **Alpha Over** | `CompositorNodeAlphaOver` | Composite CG over footage |
| **Mix** | `CompositorNodeMixRGB` | Blending operations |
| **Keying Screen** | `CompositorNodeKeyingScreen` | Clean plate generation |
| **Double Edge Mask** | `CompositorNodeDoubleEdgeMask` | Edge masking |

### 1.3 Node Positioning Best Practice

From existing code, nodes should be positioned for readable layouts:

```python
node.location = (x, y)  # x=horizontal, y=vertical
# Typical spacing: 200-300 pixels between nodes horizontally
```

---

## 2. 2D Stabilization from Point Tracks

### 2.1 Stabilization Node Chain

The stabilization workflow requires a chain of transform nodes:

```
Footage Image -> Translate -> Rotate -> Scale -> (stabilized output)
```

### 2.2 Calculating Stabilization Values from Tracks

From tracking data (REQ-TRACK-POINT), we have:
- Point positions per frame: `[(x1, y1), (x2, y2), ...]`
- Need to calculate: translation, rotation, scale per frame

**Translation Stabilization**:
```python
# Average position of all tracks in frame
avg_x = sum(track_positions_x) / len(tracks)
avg_y = sum(track_positions_y) / len(tracks)

# Reference frame (usually first frame or user-specified)
ref_x, ref_y = reference_position

# Stabilization translation
translate_x = ref_x - avg_x
translate_y = ref_y - avg_y
```

**Rotation Stabilization**:
```python
# Use multiple tracks to calculate rotation angle
# Compare angles between reference frame and current frame
angle_delta = current_angle - reference_angle
```

**Scale Stabilization**:
```python
# Compare average distance between tracks
current_scale = avg_distance_current / avg_distance_reference
```

### 2.3 Blender Stabilization Node Properties

```python
# Translate node
translate_node = tree.nodes.new('CompositorNodeTranslate')
translate_node.use_relative = False  # Use absolute pixel values
translate_node.inputs['X'].default_value = translate_x
translate_node.inputs['Y'].default_value = translate_y

# Rotate node
rotate_node = tree.nodes.new('CompositorNodeRotate')
rotate_node.filter_type = 'BILINEAR'  # or 'BICUBIC' for better quality
rotate_node.inputs['Angle'].default_value = angle_radians

# Scale node (if needed)
scale_node = tree.nodes.new('CompositorNodeScale')
scale_node.space = 'RELATIVE'  # or 'ABSOLUTE', 'RENDER_SIZE'
scale_node.inputs['X'].default_value = scale_factor
scale_node.inputs['Y'].default_value = scale_factor
```

### 2.4 Keyframing Stabilization Values

For per-frame stabilization, keyframe the node inputs:

```python
# Set current frame
bpy.context.scene.frame_set(frame_number)

# Set value and keyframe
translate_node.inputs['X'].default_value = x_value
translate_node.inputs['X'].keyframe_insert(data_path='default_value', frame=frame_number)
```

---

## 3. Corner Pin Node for Planar Tracking

### 3.1 Corner Pin Node Structure

The `CompositorNodeCornerPin` node has 4 corner inputs:

```python
corner_pin = tree.nodes.new('CompositorNodeCornerPin')

# Corner inputs (relative coordinates 0-1):
# - Upper Left (socket 1)
# - Upper Right (socket 2)
# - Lower Right (socket 3)
# - Lower Left (socket 4)

# Each corner can be connected to a Value node or set directly
# Note: Corner Pin uses relative coordinates (0-1), not absolute pixels
```

### 3.2 Converting Plane Tracks to Corner Pin

From REQ-TRACK-OBJECT planar tracking:
- 4 corners tracked over time
- Positions in pixel coordinates

**Conversion to relative coordinates**:
```python
# Given: corners_px = [(x1,y1), (x2,y2), (x3,y3), (x4,y4)]  # Pixels
# Image dimensions: width, height

corners_relative = [
    (x / width, y / height)
    for x, y in corners_px
]

# Map to corner pin sockets
# Upper Left -> corners_relative[0]
# Upper Right -> corners_relative[1]
# Lower Right -> corners_relative[2]
# Lower Left -> corners_relative[3]
```

### 3.3 Corner Pin Workflow

```
[Background Image] -> [Corner Pin] -> [Composite]
                            ^
                    [4 Corner Positions]
```

For planar insertion (e.g., screen replacement):
1. Track 4 corners of the target plane
2. Create corner pin node
3. Feed insertion image into corner pin
4. Composite corner-pinned image over background

---

## 4. Shot YAML Workflow Integration

### 4.1 Current Shot YAML Structure (from lib/cinematic/shot.py)

The existing `assemble_shot()` function handles shot configuration. For Phase 7.4, we need to extend it to support tracking.

### 4.2 Extended Shot YAML for Tracking

```yaml
shot:
  name: composite_knob_hero

  # Source footage
  footage:
    file: footage/knob_hero_4k.mp4
    frame_range: [1, 150]
    color_space: "Rec.709"

  # Tracking configuration
  tracking:
    enabled: true
    preset: high_quality          # From tracking_presets.yaml
    solve: true                    # Run camera solver

    # Reference to existing tracking data
    session_file: .gsd-state/tracking/sessions/knob_hero.yaml

    # Or: auto-track settings
    auto_detect:
      min_tracks: 100
      quality_threshold: 0.01

  # Camera from tracking
  camera:
    from_tracking: true           # Use solved camera
    tracking_solve: default       # Named solve from session

    # Overrides
    lens:
      aperture: f/4
      focus_distance: auto

  # Subject (3D element to composite)
  subject:
    artifact: neve_knob
    position: [0, 0, 0]

  # Compositing configuration
  composite:
    mode: over_footage            # over_footage, over_plate, multiply
    background_source: footage    # footage, image, none

    # Lens distortion workflow
    lens_distortion:
      apply_to_cg: true           # Distort CG to match footage
      # Or: undistort_footage: true  # Undistort footage first

    # Stabilization
    stabilization:
      enabled: false              # If true, stabilize before composite
      tracks: all                 # all, named_group

    # Shadow/alpha
    shadow_catcher: true
    film_transparent: true

  # Render
  render:
    profile: cycles_production
    passes: [beauty, shadow, alpha]
```

### 4.3 Integration Points in shot.py

The `assemble_shot()` function needs modification to:

1. **Check for tracking config**:
```python
if shot_config.get('tracking', {}).get('enabled'):
    setup_tracked_shot(shot_config)
```

2. **Load tracking data**:
```python
def setup_tracked_shot(shot_config):
    tracking_config = shot_config['tracking']

    # Load existing session or run new tracking
    if tracking_config.get('session_file'):
        session = load_tracking_session(tracking_config['session_file'])
    else:
        session = run_tracking(
            footage=shot_config['footage']['file'],
            preset=tracking_config.get('preset', 'balanced')
        )

    # Apply solved camera if requested
    if shot_config['camera'].get('from_tracking'):
        apply_solved_camera(session.solve, shot_config['camera'])

    # Setup compositor
    setup_composite_nodes(shot_config['composite'], session)
```

3. **Create compositor nodes from tracking**:
```python
def setup_composite_nodes(composite_config, tracking_session):
    scene = bpy.context.scene
    scene.use_nodes = True
    tree = scene.node_tree

    # Background footage node
    if composite_config.get('background_source') == 'footage':
        footage_node = tree.nodes.new('CompositorNodeImage')
        footage_node.image = load_footage_image(composite_config['footage_path'])

    # Stabilization nodes if enabled
    if composite_config.get('stabilization', {}).get('enabled'):
        create_stabilization_nodes(tree, tracking_session.point_tracks)

    # Alpha over for CG composite
    alpha_over = tree.nodes.new('CompositorNodeAlphaOver')

    # Link: footage -> alpha_over[1], render_layers -> alpha_over[2]
    # Output: alpha_over -> composite
```

---

## 5. Shadow Catcher Workflow

### 5.1 Shadow Catcher Setup

Shadow catchers in Cycles are materials that receive shadows but render transparent:

```python
def create_shadow_catcher_material(name="ShadowCatcher"):
    """Create shadow catcher material for compositing."""
    mat = bpy.data.materials.new(name=name)
    mat.use_nodes = True

    # For Cycles shadow catcher
    mat.shadow_method = 'CLIP'  # Blender 4.x

    # Alternative: Mix shader with transparent
    nodes = mat.node_tree.nodes
    bsdf = nodes.get('Principled BSDF')
    if bsdf:
        bsdf.inputs['Alpha'].default_value = 0.0
        # Shadow will still be captured in Shadow pass

    return mat
```

### 5.2 Shadow Catcher Object Setup

```python
def create_shadow_catcher_ground(size=10.0, location=(0, 0, 0)):
    """Create a ground plane shadow catcher."""
    bpy.ops.mesh.primitive_plane_add(size=size, location=location)
    plane = bpy.context.active_object
    plane.name = "ShadowCatcher_Ground"

    # Assign shadow catcher material
    mat = create_shadow_catcher_material()
    plane.data.materials.append(mat)

    # Settings for proper shadow catching
    plane.visible_camera = True
    plane.visible_diffuse = True
    plane.visible_glossy = True
    plane.visible_transmission = True
    plane.visible_volume_scatter = True

    return plane
```

### 5.3 Render Settings for Shadow Catcher

```python
def setup_shadow_catcher_render():
    """Configure render settings for shadow catcher composite."""
    scene = bpy.context.scene
    render = scene.render

    # Enable transparent film
    render.film_transparent = True

    # Enable shadow pass
    view_layer = scene.view_layers["ViewLayer"]
    view_layer.use_pass_shadow = True

    # Enable AO if needed
    world = scene.world
    if world and world.light_settings:
        world.light_settings.use_ambient_occlusion = True
```

### 5.4 Compositor Shadow Composite

```python
def setup_shadow_composite(tree, background_image):
    """
    Composite CG shadow over background.

    Node chain:
    Background -> [Shadow Multiply] -> Output
                    ^
    [Shadow Pass] --|
    """
    # Background image node
    bg_node = tree.nodes.new('CompositorNodeImage')
    bg_node.image = background_image

    # Get shadow pass from Render Layers
    render_layers = tree.nodes.get('Render Layers')

    # Mix node for shadow multiplication
    shadow_mix = tree.nodes.new('CompositorNodeMixRGB')
    shadow_mix.name = "ShadowComposite"
    shadow_mix.blend_type = 'MULTIPLY'
    shadow_mix.inputs['Fac'].default_value = 1.0

    # Link: shadow_pass -> mix[0], background -> mix[1]
    tree.links.new(render_layers.outputs['Shadow'], shadow_mix.inputs[0])
    tree.links.new(bg_node.outputs['Image'], shadow_mix.inputs[1])

    # Output to composite
    composite = tree.nodes.get('Composite')
    tree.links.new(shadow_mix.outputs['Image'], composite.inputs['Image'])
```

---

## 6. Resume Session Patterns

### 6.1 Session State File Structure

Based on REQUIREMENTS_TRACKING.md, session files should be stored in:
```
.gsd-state/tracking/
├── sessions/
│   └── {session_id}.yaml
└── solves/
    └── {solve_name}/
        ├── camera.yaml
        ├── tracks.yaml
        └── report.yaml
```

### 6.2 Session State Schema

```yaml
# .gsd-state/tracking/sessions/knob_hero.yaml

session:
  id: knob_hero
  created: 2026-02-19T10:00:00Z
  modified: 2026-02-19T14:30:00Z

  # Source footage
  footage:
    file: footage/knob_hero_4k.mp4
    frame_count: 150
    resolution: [3840, 2160]
    frame_rate: 24

  # Tracking progress
  tracking:
    status: in_progress  # not_started, in_progress, complete
    preset: high_quality

    # Frame ranges
    tracked_frames: [1, 75]      # Frames that have been tracked
    remaining_frames: [76, 150]  # Frames still to track

    # Track statistics
    total_tracks: 150
    active_tracks: 142
    lost_tracks: 8

  # Solve status
  solve:
    status: pending  # not_started, pending, complete, failed
    solve_name: null  # Reference to solve directory when complete

  # Last operation checkpoint
  checkpoint:
    frame: 75
    operation: "track_frame"
    timestamp: 2026-02-19T14:30:00Z
```

### 6.3 Resume Session Implementation

```python
from pathlib import Path
import yaml
from typing import Optional, Dict, Any

class TrackingSession:
    """Manages tracking session with resume capability."""

    def __init__(self, session_path: Path):
        self.session_path = session_path
        self.state = self._load_or_create_state()

    def _load_or_create_state(self) -> Dict[str, Any]:
        """Load existing session or create new."""
        if self.session_path.exists():
            with open(self.session_path, 'r') as f:
                return yaml.safe_load(f)
        else:
            return {
                'session': {'id': self.session_path.stem},
                'tracking': {'status': 'not_started'},
                'solve': {'status': 'not_started'},
                'checkpoint': {}
            }

    def save_checkpoint(self, frame: int, operation: str):
        """Save current progress for resume."""
        self.state['checkpoint'] = {
            'frame': frame,
            'operation': operation,
            'timestamp': datetime.now().isoformat()
        }
        self.state['session']['modified'] = datetime.now().isoformat()

        # Update tracked frames
        if 'tracked_frames' not in self.state['tracking']:
            self.state['tracking']['tracked_frames'] = []
        if frame not in self.state['tracking']['tracked_frames']:
            self.state['tracking']['tracked_frames'].append(frame)

        self._save()

    def get_resume_point(self) -> Optional[int]:
        """Get frame to resume from."""
        if self.state['tracking']['status'] == 'complete':
            return None

        tracked = self.state['tracking'].get('tracked_frames', [])
        if not tracked:
            return self.state['footage']['frame_range'][0]

        return max(tracked) + 1

    def _save(self):
        """Persist session state."""
        self.session_path.parent.mkdir(parents=True, exist_ok=True)
        with open(self.session_path, 'w') as f:
            yaml.dump(self.state, f, default_flow_style=False)


def resume_tracking(session_path: Path) -> TrackingSession:
    """Resume or create tracking session."""
    session = TrackingSession(session_path)

    resume_frame = session.get_resume_point()
    if resume_frame:
        print(f"Resuming tracking from frame {resume_frame}")
        # Continue tracking from resume_frame
        continue_tracking(session, resume_frame)
    else:
        print("Tracking already complete")

    return session
```

### 6.4 Integration with Shot Assembly

```python
def assemble_shot_with_tracking(shot_config: dict):
    """Assemble shot with tracking resume support."""

    tracking_config = shot_config.get('tracking', {})

    if not tracking_config.get('enabled'):
        # Standard shot assembly without tracking
        return assemble_shot(shot_config)

    # Determine session path
    shot_name = shot_config['shot']['name']
    session_path = Path(f'.gsd-state/tracking/sessions/{shot_name}.yaml')

    # Resume or create session
    session = TrackingSession(session_path)

    # Check if tracking needs to run
    if session.state['tracking']['status'] != 'complete':
        resume_frame = session.get_resume_point()
        run_tracking_with_resume(
            session=session,
            footage=shot_config['footage']['file'],
            start_frame=resume_frame,
            preset=tracking_config.get('preset', 'balanced')
        )

    # Check if solve needs to run
    if tracking_config.get('solve') and session.state['solve']['status'] != 'complete':
        run_camera_solve(session)

    # Apply solved camera to shot
    if shot_config['camera'].get('from_tracking'):
        apply_solved_camera_to_shot(session, shot_config)

    # Setup compositing
    setup_shot_compositing(shot_config, session)

    return session
```

---

## 7. Lens Distortion ST-Map Integration

### 7.1 ST-Map Concept

ST-Map (UV displacement map) stores per-pixel UV coordinates for distortion:
- R channel = U coordinate (0-1)
- G channel = V coordinate (0-1)

### 7.2 Using ST-Map in Compositor

```python
def apply_stmap_distortion(tree, stmap_image, source_image_node):
    """
    Apply lens distortion using ST-Map.

    Node chain:
    Source -> [UV Map] -> Output
                ^
    [ST-Map] ----|
    """
    # ST-Map image node
    stmap_node = tree.nodes.new('CompositorNodeImage')
    stmap_node.image = stmap_image

    # UV Map node (uses ST-Map as coordinate source)
    uv_map_node = tree.nodes.new('CompositorNodeMapUV')
    uv_map_node.filter_type = 'BILINEAR'

    # Link ST-Map to UV Vector input
    tree.links.new(stmap_node.outputs['Image'], uv_map_node.inputs['Vector'])

    # Link source to Image input
    tree.links.new(source_image_node.outputs['Image'], uv_map_node.inputs['Image'])

    return uv_map_node
```

### 7.3 ST-Map Generation (from Phase 7.2)

The ST-Map generation from Phase 7.2 (`lib/cinematic/tracking/st_map.py`) provides:

```python
def generate_stmap_for_footage(footage_path: Path, distortion_params: dict) -> Path:
    """Generate ST-Map for lens distortion workflow."""
    # Uses distortion K1, K2, etc. from calibration
    # Outputs EXR file with UV coordinates
    pass
```

---

## 8. Composite Mode Rendering

### 8.1 Composite Mode Options

| Mode | Description | Node Chain |
|------|-------------|------------|
| `over_footage` | CG rendered over background footage | AlphaOver |
| `over_plate` | CG over static image plate | AlphaOver |
| `multiply` | CG multiplied with background | MixRGB (Multiply) |
| `add` | Additive blend (glows) | MixRGB (Add) |
| `screen` | Screen blend | MixRGB (Screen) |

### 8.2 Composite Mode Implementation

```python
def setup_composite_mode(tree, mode: str, background_node, cg_node):
    """Setup compositor for specific blend mode."""

    if mode == 'over_footage' or mode == 'over_plate':
        # Alpha Over composite
        mix = tree.nodes.new('CompositorNodeAlphaOver')
        mix.name = "Composite_Over"

        # CG -> socket 1 (foreground), BG -> socket 2 (background)
        tree.links.new(cg_node.outputs['Image'], mix.inputs[1])
        tree.links.new(background_node.outputs['Image'], mix.inputs[2])

        return mix

    elif mode == 'multiply':
        # Multiply blend
        mix = tree.nodes.new('CompositorNodeMixRGB')
        mix.name = "Composite_Multiply"
        mix.blend_type = 'MULTIPLY'
        mix.inputs['Fac'].default_value = 1.0

        tree.links.new(cg_node.outputs['Image'], mix.inputs[0])  # Fac override
        tree.links.new(background_node.outputs['Image'], mix.inputs[1])
        tree.links.new(cg_node.outputs['Image'], mix.inputs[2])

        return mix

    # ... other modes
```

---

## 9. Key Risks and Considerations

### 9.1 Technical Risks

| Risk | Impact | Mitigation |
|------|--------|------------|
| **Tracking data format mismatch** | Compositor nodes get wrong values | Validate data types before node creation |
| **Frame range mismatch** | Compositor reads wrong frames | Verify footage frame count matches tracking |
| **Color space issues** | CG doesn't match footage | Apply color management transforms |
| **Memory usage with long footage** | Blender crashes with long clips | Use proxies or clip to needed range |
| **ST-Map precision** | Visible distortion artifacts | Use EXR with float16/32 precision |

### 9.2 API Limitations

1. **No native 2D stabilization node** - Must build from Translate/Rotate/Scale nodes
2. **Corner Pin uses relative coords** - Must convert from absolute pixel positions
3. **No direct tracking data access in compositor** - Must export to keyframes
4. **Blender's movie clip API is separate** - Tracking data is in MovieClip, not Compositor

### 9.3 Performance Considerations

- **Keyframe density**: Per-frame keyframes can be heavy; consider interpolation modes
- **Compositor tree complexity**: Long node chains slow viewport; use node groups
- **Footage caching**: Large footage files need disk cache; set up properly

---

## 10. Implementation Recommendations

### 10.1 Module Structure

```
lib/cinematic/
├── tracking/
│   ├── compositor.py       # NEW: Compositor node creation from tracking
│   ├── shot_integration.py # NEW: Shot assembly integration
│   └── session.py          # NEW: Resume session management
```

### 10.2 Priority Order for Planning

1. **Session management** - Foundation for resume capability
2. **Shot YAML extension** - Add tracking config parsing
3. **Compositor node creation** - Stabilization, corner pin
4. **Shadow catcher workflow** - Complete composite pipeline
5. **Lens distortion ST-Map** - Integration with Phase 7.2

### 10.3 Test Coverage

Each feature needs test cases:
- Stabilization accuracy (pixel-level comparison)
- Corner pin transformation correctness
- Session save/resume persistence
- Shot YAML parsing with tracking config
- Shadow catcher alpha output
- ST-Map application accuracy

---

## 11. Dependencies on Previous Phases

| Phase | Dependency | Required Feature |
|-------|------------|------------------|
| **7.1** | Camera solver | `camera_solver.py` - Solved camera data |
| **7.1** | Point tracking | `point_tracker.py` - Track positions |
| **7.2** | ST-Map generation | `st_map.py` - UV distortion map |
| **6.1** | Cinematic camera | `camera.py` - Camera integration |
| **6.0** | Shot assembly | `shot.py` - YAML parsing, assembly |

---

## Summary

Phase 7.4 requires understanding of:

1. **Blender Compositor Node API** - Types, properties, linking
2. **2D Stabilization** - Calculating and applying translation/rotation/scale
3. **Corner Pin** - Planar tracking insertion
4. **Shot YAML Integration** - Extending existing shot assembly
5. **Shadow Catcher** - Material setup and render pass handling
6. **Session Resume** - State persistence and checkpointing

The existing codebase provides good patterns in `lens_fx.py`, `color.py`, and `nodekit.py` for compositor node creation. The main implementation work is connecting tracking data to compositor nodes and integrating with the shot assembly workflow.
