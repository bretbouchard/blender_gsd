---
phase: 06.9-camera-matching
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - lib/cinematic/types.py
  - lib/cinematic/preset_loader.py
autonomous: true

must_haves:
  truths:
    - "CameraMatchConfig supports reference image loading"
    - "TrackingImportConfig supports Nuke/After Effects formats"
    - "AudioSyncConfig supports beat marker import"
  artifacts:
    - path: "lib/cinematic/types.py"
      provides: "Camera matching and audio sync types"
      contains: "CameraMatchConfig"
    - path: "lib/cinematic/preset_loader.py"
      provides: "Camera profile loaders"
      exports: ["get_camera_profile", "list_camera_profiles"]
  key_links:
    - from: "lib/cinematic/preset_loader.py"
      to: "configs/cinematic/tracking/camera_profiles.yaml"
      via: "load_preset()"
---

<objective>
Add camera matching and audio sync types and loaders.

Purpose: Provide type definitions for camera matching from reference images, tracking data import, and audio sync with beat markers (REQ-CINE-MATCH, REQ-CINE-AUDIO).
Output: CameraMatchConfig, TrackingImportConfig, AudioSyncConfig dataclasses and camera profile loaders.
</objective>

<execution_context>
@/Users/bretbouchard/.claude/get-shit-done/workflows/execute-plan.md
@/Users/bretbouchard/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

# Existing patterns to follow
@lib/cinematic/types.py
@lib/cinematic/preset_loader.py

# Requirements
@.planning/REQUIREMENTS_CINEMATIC.md (REQ-CINE-MATCH, REQ-CINE-AUDIO)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add camera matching types to types.py</name>
  <files>lib/cinematic/types.py</files>
  <action>
Add camera matching and audio sync dataclasses after ShotAssemblyConfig (around line 1765).

```python
@dataclass
class CameraMatchConfig:
    """
    Camera matching configuration (REQ-CINE-MATCH).

    Allows matching a Blender camera to a reference image by analyzing
    perspective, focal length, and camera position.

    Attributes:
        reference_image: Path to reference image for matching
        focal_length_estimate: Estimated focal length (0 = auto-detect)
        horizon_line: Y position of horizon line (0-1 normalized)
        vanishing_points: Detected/calculated vanishing points
        auto_detect_focal: Automatically estimate focal length
        auto_detect_horizon: Automatically detect horizon line
        match_mode: Matching mode (perspective, orthographic, isometric)
        tolerance: Matching tolerance in pixels
        subject_bounds: Optional subject bounding box in image (for scale ref)
    """
    reference_image: str = ""
    focal_length_estimate: float = 0.0  # 0 = auto
    horizon_line: float = 0.5  # Normalized 0-1
    vanishing_points: List[Tuple[float, float]] = field(default_factory=list)
    auto_detect_focal: bool = True
    auto_detect_horizon: bool = True
    match_mode: str = "perspective"  # perspective, orthographic, isometric
    tolerance: float = 5.0  # Pixels
    subject_bounds: Optional[Tuple[float, float, float, float]] = None  # x1, y1, x2, y2

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for serialization."""
        return {
            "reference_image": self.reference_image,
            "focal_length_estimate": self.focal_length_estimate,
            "horizon_line": self.horizon_line,
            "vanishing_points": [list(vp) for vp in self.vanishing_points],
            "auto_detect_focal": self.auto_detect_focal,
            "auto_detect_horizon": self.auto_detect_horizon,
            "match_mode": self.match_mode,
            "tolerance": self.tolerance,
            "subject_bounds": list(self.subject_bounds) if self.subject_bounds else None,
        }

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "CameraMatchConfig":
        """Create from dictionary."""
        vps_data = data.get("vanishing_points", [])
        vps = [tuple(vp) for vp in vps_data] if vps_data else []
        bounds = data.get("subject_bounds")
        if bounds:
            bounds = tuple(bounds)

        return cls(
            reference_image=data.get("reference_image", ""),
            focal_length_estimate=data.get("focal_length_estimate", 0.0),
            horizon_line=data.get("horizon_line", 0.5),
            vanishing_points=vps,
            auto_detect_focal=data.get("auto_detect_focal", True),
            auto_detect_horizon=data.get("auto_detect_horizon", True),
            match_mode=data.get("match_mode", "perspective"),
            tolerance=data.get("tolerance", 5.0),
            subject_bounds=bounds,
        )


@dataclass
class TrackingImportConfig:
    """
    Tracking data import configuration (REQ-CINE-MATCH).

    Supports importing camera tracking data from external match-move
    software like Nuke, After Effects, SynthEyes, etc.

    Supported Formats:
    - nuke_chan: Nuke .chan files
    - fbx: FBX camera export
    - alembic: Alembic .abc camera
    - bvh: BVH motion capture
    - json: Custom JSON format

    Attributes:
        format: Import format (nuke_chan, fbx, alembic, bvh, json)
        file_path: Path to tracking data file
        frame_offset: Frame number offset
        scale_factor: Scale multiplier for imported data
        coordinate_system: Source coordinate system (y_up, z_up)
        interpolate: Interpolate between keyframes
        smooth_rotation: Apply smoothing to rotation data
    """
    format: str = "fbx"  # nuke_chan, fbx, alembic, bvh, json
    file_path: str = ""
    frame_offset: int = 0
    scale_factor: float = 1.0
    coordinate_system: str = "y_up"  # y_up, z_up
    interpolate: bool = True
    smooth_rotation: float = 0.0  # Smoothing factor 0-1

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for serialization."""
        return {
            "format": self.format,
            "file_path": self.file_path,
            "frame_offset": self.frame_offset,
            "scale_factor": self.scale_factor,
            "coordinate_system": self.coordinate_system,
            "interpolate": self.interpolate,
            "smooth_rotation": self.smooth_rotation,
        }

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "TrackingImportConfig":
        """Create from dictionary."""
        return cls(
            format=data.get("format", "fbx"),
            file_path=data.get("file_path", ""),
            frame_offset=data.get("frame_offset", 0),
            scale_factor=data.get("scale_factor", 1.0),
            coordinate_system=data.get("coordinate_system", "y_up"),
            interpolate=data.get("interpolate", True),
            smooth_rotation=data.get("smooth_rotation", 0.0),
        )


@dataclass
class AudioSyncConfig:
    """
    Audio sync configuration (REQ-CINE-AUDIO).

    Supports loading audio tracks and placing beat markers for
    animation timing and synchronization.

    Attributes:
        audio_file: Path to audio file
        bpm: Beats per minute (0 = auto-detect)
        time_signature: Time signature (4/4 default)
        beat_markers: List of frame numbers for beat markers
        auto_detect_bpm: Automatically detect BPM from audio
        offset_frames: Frame offset for sync
        markers: Named markers at specific frames
    """
    audio_file: str = ""
    bpm: float = 0.0  # 0 = auto-detect
    time_signature: Tuple[int, int] = (4, 4)
    beat_markers: List[int] = field(default_factory=list)
    auto_detect_bpm: bool = True
    offset_frames: int = 0
    markers: Dict[str, int] = field(default_factory=dict)  # name -> frame

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for serialization."""
        return {
            "audio_file": self.audio_file,
            "bpm": self.bpm,
            "time_signature": list(self.time_signature),
            "beat_markers": self.beat_markers,
            "auto_detect_bpm": self.auto_detect_bpm,
            "offset_frames": self.offset_frames,
            "markers": self.markers,
        }

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "AudioSyncConfig":
        """Create from dictionary."""
        return cls(
            audio_file=data.get("audio_file", ""),
            bpm=data.get("bpm", 0.0),
            time_signature=tuple(data.get("time_signature", (4, 4))),
            beat_markers=data.get("beat_markers", []),
            auto_detect_bpm=data.get("auto_detect_bpm", True),
            offset_frames=data.get("offset_frames", 0),
            markers=data.get("markers", {}),
        )


@dataclass
class CameraProfile:
    """
    Camera device profile for realistic camera matching.

    Stores intrinsic parameters for specific camera/lens combinations
    to improve match accuracy.

    Attributes:
        name: Profile name (e.g., "iPhone_15_Pro_Main", "Sony_A7III_50mm")
        sensor_width: Sensor width in mm
        sensor_height: Sensor height in mm
        focal_length: Lens focal length in mm
        distortion_model: Lens distortion model (none, simple, brown_conrady)
        distortion_params: Distortion coefficients
        crop_factor: Sensor crop factor
        aspect_ratio: Pixel aspect ratio
    """
    name: str = ""
    sensor_width: float = 36.0
    sensor_height: float = 24.0
    focal_length: float = 50.0
    distortion_model: str = "none"
    distortion_params: List[float] = field(default_factory=list)
    crop_factor: float = 1.0
    aspect_ratio: float = 1.0

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for serialization."""
        return {
            "name": self.name,
            "sensor_width": self.sensor_width,
            "sensor_height": self.sensor_height,
            "focal_length": self.focal_length,
            "distortion_model": self.distortion_model,
            "distortion_params": self.distortion_params,
            "crop_factor": self.crop_factor,
            "aspect_ratio": self.aspect_ratio,
        }

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "CameraProfile":
        """Create from dictionary."""
        return cls(
            name=data.get("name", ""),
            sensor_width=data.get("sensor_width", 36.0),
            sensor_height=data.get("sensor_height", 24.0),
            focal_length=data.get("focal_length", 50.0),
            distortion_model=data.get("distortion_model", "none"),
            distortion_params=data.get("distortion_params", []),
            crop_factor=data.get("crop_factor", 1.0),
            aspect_ratio=data.get("aspect_ratio", 1.0),
        )
```
  </action>
  <verify>python3 -c "
from lib.cinematic.types import CameraMatchConfig, TrackingImportConfig, AudioSyncConfig, CameraProfile

# Test instantiation
cm = CameraMatchConfig(reference_image='test.jpg')
assert cm.reference_image == 'test.jpg'
assert cm.auto_detect_focal == True

ti = TrackingImportConfig(format='fbx', file_path='track.fbx')
assert ti.format == 'fbx'

as_ = AudioSyncConfig(audio_file='music.mp3', bpm=120)
assert as_.bpm == 120

cp = CameraProfile(name='test_profile')
assert cp.name == 'test_profile'

# Test round-trip
data = cm.to_dict()
cm2 = CameraMatchConfig.from_dict(data)
assert cm2.reference_image == cm.reference_image

print('Camera matching types OK')
"</verify>
  <done>CameraMatchConfig, TrackingImportConfig, AudioSyncConfig, CameraProfile dataclasses</done>
</task>

<task type="auto">
  <name>Task 2: Add camera profile loaders to preset_loader.py</name>
  <files>lib/cinematic/preset_loader.py</files>
  <action>
Add camera profile loader functions following existing patterns.

Add constant:
```python
# Camera profile configuration
CAMERA_PROFILE_ROOT = Path("configs/cinematic/tracking")
```

Add functions:
```python
def get_camera_profile(name: str) -> Dict[str, Any]:
    \"\"\"Load a camera device profile by name.\"\"\"
    path = CAMERA_PROFILE_ROOT / "camera_profiles.yaml"
    if not path.exists():
        raise FileNotFoundError(f"Camera profiles file not found: {path}")

    with open(path, "r", encoding="utf-8") as f:
        data = yaml.safe_load(f)

    profiles = data.get("profiles", {})
    if name not in profiles:
        available = list(profiles.keys())
        raise ValueError(f"Camera profile '{name}' not found. Available: {available}")

    return profiles[name]


def list_camera_profiles() -> List[str]:
    \"\"\"List available camera profiles.\"\"\"
    path = CAMERA_PROFILE_ROOT / "camera_profiles.yaml"
    if not path.exists():
        return []

    with open(path, "r", encoding="utf-8") as f:
        data = yaml.safe_load(f)

    return sorted(data.get("profiles", {}).keys())
```
  </action>
  <verify>python3 -c "
from lib.cinematic.preset_loader import CAMERA_PROFILE_ROOT, get_camera_profile, list_camera_profiles
print('Camera profile loader imports OK')
"</verify>
  <done>Camera profile loader functions</done>
</task>

</tasks>

<verification>
1. CameraMatchConfig with reference image and vanishing point support
2. TrackingImportConfig with format options
3. AudioSyncConfig with beat markers
4. CameraProfile for device profiles
5. Profile loader functions exist
</verification>

<success_criteria>
- All four dataclasses serialize correctly
- Camera profile loaders functional
- Pattern matches existing loaders
</success_criteria>

<output>
After completion, create `.planning/phases/06.9-camera-matching/06.9-01-SUMMARY.md`
</output>
