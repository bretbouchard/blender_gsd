---
phase: 07.2-footage-profiles
plan: 03
type: execute
wave: 3
depends_on: ["07.2-01", "07.2-02"]
files_modified:
  - lib/cinematic/tracking/distortion.py
  - lib/cinematic/tracking/vanishing_points.py
autonomous: true
# SCOPE NOTE: Creates 2 new modules with ~600 lines total. Heavy tasks but
# acceptable for Wave 3. Executor should expect longer execution time.

must_haves:
  truths:
    - "ST-Map generation creates UV coordinate maps for compositing"
    - "Vanishing point detection estimates focal length from image lines"
    - "Brown-Conrady distortion model is already implemented in calibration.py"
  artifacts:
    - path: "lib/cinematic/tracking/distortion.py"
      provides: "ST-Map generation for compositing workflows"
      exports: ["STMapGenerator", "generate_st_map", "save_st_map_exr"]
    - path: "lib/cinematic/tracking/vanishing_points.py"
      provides: "Focal length estimation from vanishing points"
      exports: ["VanishingPointDetector", "detect_vanishing_points", "estimate_focal_length"]
  key_links:
    - from: "STMapGenerator"
      to: "calibration.LensDistortion"
      via: "uses Brown-Conrady implementation"
      pattern: "from.*calibration.*import"
    - from: "VanishingPointDetector"
      to: "CameraProfile"
      via: "estimates focal_length_mm"
      pattern: "estimate.*focal_length"
---

<objective>
Create distortion.py for ST-Map generation and vanishing_points.py for focal length estimation.

Purpose: ST-Maps enable compositing workflows to apply lens distortion to footage/CG. Vanishing point detection estimates focal length when camera profile is unknown.
Output: New distortion.py with STMapGenerator and vanishing_points.py with VanishingPointDetector.
</objective>

<execution_context>
@/Users/bretbouchard/.claude/get-shit-done/workflows/execute-plan.md
@/Users/bretbouchard/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07.2-footage-profiles/07.2-RESEARCH.md

# Reference existing modules
@lib/cinematic/tracking/types.py
@lib/cinematic/tracking/calibration.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create distortion.py with STMapGenerator</name>
  <files>lib/cinematic/tracking/distortion.py</files>
  <action>
    Create new module for ST-Map generation:

    ```python
    """
    ST-Map Generation for Lens Distortion Compositing

    ST-Maps (Spatial Transform Maps) are UV coordinate maps used in
    compositing to apply lens distortion/undistortion to footage or CG.

    The map encodes where each output pixel should sample from in the
    source image. R channel = U coordinate, G channel = V coordinate.
    """

    from __future__ import annotations
    from dataclasses import dataclass, field
    from typing import Dict, Any, Optional, Tuple, List
    from pathlib import Path
    import math

    from .types import CameraProfile
    from .calibration import DistortionCoefficients, LensDistortion

    # Blender API guard
    try:
        import numpy as np
        HAS_NUMPY = True
    except ImportError:
        HAS_NUMPY = False
        np = None


    @dataclass
    class STMapConfig:
        """
        Configuration for ST-Map generation.

        Attributes:
            width: Output width in pixels
            height: Output height in pixels
            fx, fy: Focal length in pixels
            cx, cy: Principal point in pixels (usually image center)
            undistort: If True, map undistorts source; if False, applies distortion
            normalize: If True, output coordinates are 0-1; if False, pixel coordinates
        """
        width: int = 1920
        height: int = 1080
        fx: float = 1000.0
        fy: float = 1000.0
        cx: float = 960.0
        cy: float = 540.0
        undistort: bool = True
        normalize: bool = True

        def to_dict(self) -> Dict[str, Any]:
            return {
                "width": self.width,
                "height": self.height,
                "fx": self.fx,
                "fy": self.fy,
                "cx": self.cx,
                "cy": self.cy,
                "undistort": self.undistort,
                "normalize": self.normalize,
            }

        @classmethod
        def from_profile(
            cls,
            profile: CameraProfile,
            width: int,
            height: int,
            undistort: bool = True,
        ) -> STMapConfig:
            """Create config from camera profile."""
            # Calculate focal length in pixels from profile
            fx = width * profile.focal_length / profile.sensor_width
            fy = height * profile.focal_length / profile.sensor_height

            return cls(
                width=width,
                height=height,
                fx=fx,
                fy=fy,
                cx=width / 2 + profile.cx * width,
                cy=height / 2 + profile.cy * height,
                undistort=undistort,
            )


    class STMapGenerator:
        """
        Generate ST-Maps for lens distortion compositing.

        ST-Maps are used in Nuke, After Effects, and Blender compositor
        to apply lens distortion to footage or CG elements.
        """

        def __init__(self, config: STMapConfig):
            self.config = config

        def generate(
            self,
            coeffs: DistortionCoefficients,
        ) -> Any:  # numpy array or dict
            """
            Generate ST-Map for given distortion coefficients.

            Returns:
                numpy array (H, W, 4) where:
                R = U coordinate (0-1 if normalized)
                G = V coordinate (0-1 if normalized)
                B = 0
                A = 1
            """
            if not HAS_NUMPY:
                return self._generate_dict(coeffs)

            return self._generate_numpy(coeffs)

        def _generate_numpy(
            self,
            coeffs: DistortionCoefficients,
        ) -> Any:
            """Generate ST-Map using NumPy."""
            import numpy as np

            w = self.config.width
            h = self.config.height

            # Create coordinate grids
            u = np.arange(w, dtype=np.float32)
            v = np.arange(h, dtype=np.float32)
            u, v = np.meshgrid(u, v)

            # Convert to normalized coordinates centered at principal point
            x = (u - self.config.cx) / self.config.fx
            y = (v - self.config.cy) / self.config.fy

            if self.config.undistort:
                # Map from distorted to undistorted
                x_out, y_out = LensDistortion.remove_brown_conrady(
                    x, y, coeffs, iterations=10
                )
            else:
                # Map from undistorted to distorted
                x_out, y_out = LensDistortion.apply_brown_conrady(
                    x, y, coeffs
                )

            # Convert back to pixel coordinates
            u_out = x_out * self.config.fx + self.config.cx
            v_out = y_out * self.config.fy + self.config.cy

            # Normalize to 0-1 range
            if self.config.normalize:
                u_norm = u_out / w
                v_norm = v_out / h
            else:
                u_norm = u_out
                v_norm = v_out

            # Create RGBA output
            st_map = np.zeros((h, w, 4), dtype=np.float32)
            st_map[:, :, 0] = u_norm  # R = U
            st_map[:, :, 1] = v_norm  # G = V
            st_map[:, :, 3] = 1.0     # A = 1

            return st_map

        def _generate_dict(self, coeffs: DistortionCoefficients) -> Dict[str, Any]:
            """Fallback dict output when NumPy unavailable."""
            return {
                "config": self.config.to_dict(),
                "coefficients": coeffs.to_dict(),
                "note": "NumPy not available - generate requires NumPy",
            }

        def save_exr(self, st_map: Any, output_path: str) -> bool:
            """
            Save ST-Map as EXR file.

            EXR is preferred for ST-Maps because it supports 32-bit float
            precision required for accurate UV coordinates.
            """
            try:
                import cv2
                return cv2.imwrite(output_path, st_map)
            except ImportError:
                return False


    def generate_st_map(
        profile: CameraProfile,
        width: int,
        height: int,
        undistort: bool = True,
    ) -> Any:
        """
        Convenience function to generate ST-Map from camera profile.

        Args:
            profile: CameraProfile with distortion coefficients
            width: Output width in pixels
            height: Output height in pixels
            undistort: If True, map undistorts source

        Returns:
            ST-Map as numpy array (H, W, 4)
        """
        config = STMapConfig.from_profile(profile, width, height, undistort)
        coeffs = DistortionCoefficients.from_profile(profile)
        generator = STMapGenerator(config)
        return generator.generate(coeffs)


    def save_st_map_exr(st_map: Any, output_path: str) -> bool:
        """
        Convenience function to save ST-Map as EXR.

        Args:
            st_map: ST-Map numpy array
            output_path: Output file path

        Returns:
            True if successful
        """
        try:
            import cv2
            return cv2.imwrite(output_path, st_map)
        except ImportError:
            return False
    ```

    Reuse LensDistortion from calibration.py for Brown-Conrady math.
  </action>
  <verify>grep -q "class STMapGenerator" lib/cinematic/tracking/distortion.py && grep -q "def generate_st_map" lib/cinematic/tracking/distortion.py && echo "STMapGenerator and generate_st_map found"</verify>
  <done>STMapGenerator class with generate() and save_exr() methods exist, generate_st_map() convenience function available</done>
</task>

<task type="auto">
  <name>Task 2: Create vanishing_points.py for focal length estimation</name>
  <files>lib/cinematic/tracking/vanishing_points.py</files>
  <action>
    Create new module for vanishing point detection and focal length estimation:

    ```python
    """
    Vanishing Point Detection for Focal Length Estimation

    Detects vanishing points from line intersections in images and
    estimates camera focal length using the orthogonality constraint.

    Based on the principle that for two orthogonal directions, their
    vanishing points satisfy: f^2 = -(v1 - c) . (v2 - c)
    where f is focal length and c is principal point.
    """

    from __future__ import annotations
    from dataclasses import dataclass, field
    from typing import Dict, Any, Optional, Tuple, List
    from pathlib import Path
    import math

    from .types import CameraProfile

    # OpenCV guard
    try:
        import cv2
        import numpy as np
        HAS_OPENCV = True
    except ImportError:
        HAS_OPENCV = False
        cv2 = None
        np = None


    @dataclass
    class VanishingPoint:
        """
        Detected vanishing point.

        Attributes:
            x, y: Vanishing point coordinates
            confidence: Detection confidence (0-1)
            num_lines: Number of lines contributing to this VP
        """
        x: float
        y: float
        confidence: float = 0.0
        num_lines: int = 0

        def to_dict(self) -> Dict[str, Any]:
            return {
                "x": self.x,
                "y": self.y,
                "confidence": self.confidence,
                "num_lines": self.num_lines,
            }

        @classmethod
        def from_dict(cls, data: Dict[str, Any]) -> VanishingPoint:
            return cls(
                x=data.get("x", 0.0),
                y=data.get("y", 0.0),
                confidence=data.get("confidence", 0.0),
                num_lines=data.get("num_lines", 0),
            )


    class VanishingPointDetector:
        """
        Detect vanishing points from line intersections.

        Uses Canny edge detection and Hough line transform to find lines,
        then clusters intersections to find vanishing points.
        """

        def __init__(
            self,
            canny_threshold1: int = 50,
            canny_threshold2: int = 150,
            hough_threshold: int = 100,
            min_line_length: int = 50,
            max_line_gap: int = 10,
        ):
            self.canny_threshold1 = canny_threshold1
            self.canny_threshold2 = canny_threshold2
            self.hough_threshold = hough_threshold
            self.min_line_length = min_line_length
            self.max_line_gap = max_line_gap

        def detect(
            self,
            image: Any,  # numpy array or path
        ) -> List[VanishingPoint]:
            """
            Detect vanishing points from image.

            Args:
                image: Image as numpy array (H, W, 3) or file path

            Returns:
                List of detected VanishingPoint objects
            """
            if not HAS_OPENCV:
                return []

            return self._detect_opencv(image)

        def _detect_opencv(self, image: Any) -> List[VanishingPoint]:
            """OpenCV-based vanishing point detection."""
            import cv2
            import numpy as np

            # Load image if path provided
            if isinstance(image, (str, Path)):
                image = cv2.imread(str(image))
                if image is None:
                    return []

            # Convert to grayscale
            if len(image.shape) == 3:
                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            else:
                gray = image

            h, w = gray.shape

            # Edge detection
            edges = cv2.Canny(
                gray,
                self.canny_threshold1,
                self.canny_threshold2,
                apertureSize=3,
            )

            # Line detection using Hough transform
            lines = cv2.HoughLinesP(
                edges,
                rho=1,
                theta=np.pi / 180,
                threshold=self.hough_threshold,
                minLineLength=self.min_line_length,
                maxLineGap=self.max_line_gap,
            )

            if lines is None or len(lines) < 4:
                return []

            # Convert lines to point-direction form
            line_points = []
            for line in lines:
                x1, y1, x2, y2 = line[0]
                dx = x2 - x1
                dy = y2 - y1
                length = math.sqrt(dx * dx + dy * dy)
                if length > 0:
                    dx /= length
                    dy /= length
                    line_points.append((x1, y1, dx, dy))

            # Find intersections
            intersections = []
            for i, (x1, y1, dx1, dy1) in enumerate(line_points):
                for j, (x2, y2, dx2, dy2) in enumerate(line_points[i+1:], i+1):
                    # Line-line intersection
                    det = dx1 * dy2 - dy1 * dx2
                    if abs(det) < 1e-6:
                        continue  # Parallel lines

                    t = ((x2 - x1) * dy2 - (y2 - y1) * dx2) / det
                    px = x1 + t * dx1
                    py = y1 + t * dy1

                    # Keep intersections in reasonable range
                    if -w < px < 2 * w and -h < py < 2 * h:
                        intersections.append((px, py))

            if not intersections:
                return []

            # Cluster intersections using k-means
            intersections = np.array(intersections, dtype=np.float32)

            # Determine number of clusters (up to 3 for Manhattan world)
            k = min(3, len(intersections) // 3)
            if k < 1:
                return []

            criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)
            _, labels, centers = cv2.kmeans(
                intersections,
                k,
                None,
                criteria,
                10,
                cv2.KMEANS_PP_CENTERS,
            )

            # Create vanishing points from significant clusters
            vanishing_points = []
            for i, center in enumerate(centers):
                cluster_size = np.sum(labels.flatten() == i)
                if cluster_size >= 3:
                    vp = VanishingPoint(
                        x=float(center[0]),
                        y=float(center[1]),
                        confidence=min(1.0, cluster_size / 20.0),
                        num_lines=int(cluster_size),
                    )
                    vanishing_points.append(vp)

            return vanishing_points


    def estimate_focal_length(
        vanishing_points: List[VanishingPoint],
        image_width: int,
        image_height: int,
        sensor_width: float = 36.0,
    ) -> float:
        """
        Estimate focal length from orthogonal vanishing points.

        Uses the orthogonality constraint: if two vanishing points
        correspond to orthogonal directions, then:
            f^2 = -((vp1 - c) . (vp2 - c))
        where c is the principal point (image center).

        Args:
            vanishing_points: List of detected vanishing points
            image_width: Image width in pixels
            image_height: Image height in pixels
            sensor_width: Sensor width in mm for conversion

        Returns:
            Estimated focal length in mm
        """
        if len(vanishing_points) < 2:
            return 50.0  # Default

        # Principal point (assume image center)
        cx = image_width / 2
        cy = image_height / 2

        # Try all pairs of vanishing points
        focal_estimates = []

        for i in range(len(vanishing_points)):
            for j in range(i + 1, len(vanishing_points)):
                vp1 = vanishing_points[i]
                vp2 = vanishing_points[j]

                # Translate to principal point
                v1 = np.array([vp1.x - cx, vp1.y - cy]) if HAS_OPENCV else [vp1.x - cx, vp1.y - cy]
                v2 = np.array([vp2.x - cx, vp2.y - cy]) if HAS_OPENCV else [vp2.x - cx, vp2.y - cy]

                # Dot product for orthogonality test
                dot = v1[0] * v2[0] + v1[1] * v2[1]

                if dot < 0:  # Orthogonal directions
                    f_pixels = math.sqrt(-dot)
                    focal_estimates.append(f_pixels)

        if not focal_estimates:
            return 50.0

        # Use median estimate
        if HAS_OPENCV:
            f_pixels = float(np.median(focal_estimates))
        else:
            f_pixels = sorted(focal_estimates)[len(focal_estimates) // 2]

        # Convert to mm (f_mm = f_pixels * sensor_width / image_width)
        f_mm = f_pixels * sensor_width / image_width

        # Clamp to reasonable range
        return max(14.0, min(200.0, f_mm))


    def detect_vanishing_points(
        image: Any,
        canny_threshold1: int = 50,
        canny_threshold2: int = 150,
    ) -> List[VanishingPoint]:
        """
        Convenience function to detect vanishing points from image.

        Args:
            image: Image as numpy array or file path
            canny_threshold1, canny_threshold2: Canny edge thresholds

        Returns:
            List of detected VanishingPoint objects
        """
        detector = VanishingPointDetector(
            canny_threshold1=canny_threshold1,
            canny_threshold2=canny_threshold2,
        )
        return detector.detect(image)
    ```

    The module provides both class-based and functional APIs.
  </action>
  <verify>grep -q "class VanishingPointDetector" lib/cinematic/tracking/vanishing_points.py && grep -q "def estimate_focal_length" lib/cinematic/tracking/vanishing_points.py && echo "VanishingPointDetector and estimate_focal_length found"</verify>
  <done>VanishingPointDetector class and estimate_focal_length() function exist</done>
</task>

</tasks>

<verification>
- STMapGenerator class generates UV coordinate maps
- ST-Map output is (H, W, 4) with R=U, G=V, A=1
- VanishingPointDetector finds vanishing points from line intersections
- estimate_focal_length() estimates mm focal length from VP pairs
- Both modules handle missing NumPy/OpenCV gracefully
</verification>

<success_criteria>
- STMapGenerator.generate() produces correct UV coordinate maps
- ST-Maps can be saved as EXR files
- VanishingPointDetector detects vanishing points in images with strong lines
- Focal length estimation returns reasonable mm values
</success_criteria>

<output>
After completion, create `.planning/phases/07.2-footage-profiles/07.2-03-SUMMARY.md`
</output>
