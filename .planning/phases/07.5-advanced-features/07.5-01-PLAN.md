---
phase: 07.5-advanced-features
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - lib/cinematic/batch.py
  - lib/cinematic/tracking/types.py
autonomous: true

must_haves:
  truths:
    - "Batch jobs can be configured from YAML"
    - "Jobs execute in parallel using subprocess isolation"
    - "Failed jobs can resume from checkpoint"
    - "Batch reports summarize all job results"
  artifacts:
    - path: "lib/cinematic/batch.py"
      provides: "Batch processing system with parallel execution"
      exports: ["BatchJob", "BatchConfig", "BatchResult", "BatchProcessor"]
    - path: "lib/cinematic/tracking/types.py"
      provides: "Extended types for batch processing"
  key_links:
    - from: "BatchProcessor"
      to: "subprocess"
      via: "ProcessPoolExecutor"
      pattern: "ProcessPoolExecutor"
---

<objective>
Implement batch processing system for parallel shot execution with checkpoint-based resume capability.

Purpose: Enable efficient processing of multiple tracking/render jobs in parallel with automatic recovery from failures.
Output: `lib/cinematic/batch.py` with full batch processing capabilities.
</objective>

<execution_context>
@/Users/bretbouchard/.claude/get-shit-done/workflows/execute-plan.md
@/Users/bretbouchard/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

# Research reference
@.planning/phases/07.5-advanced-features/07.5-RESEARCH.md

# Existing tracking types to extend
@lib/cinematic/tracking/types.py
</context>

<tasks>

<task type="auto">
  <name>Add Batch Types to tracking/types.py</name>
  <files>lib/cinematic/tracking/types.py</files>
  <action>
    Add the following dataclasses to types.py (after existing classes):

    ```python
    @dataclass
    class BatchJob:
        """
        Single batch job definition.

        Attributes:
            id: Unique job identifier
            name: Human-readable job name
            shot_config: Path to shot YAML configuration
            output_path: Output directory for job results
            status: Current job status (pending, running, completed, failed, skipped)
            error: Error message if failed
            start_time: ISO timestamp when job started
            end_time: ISO timestamp when job completed
            retry_count: Number of retry attempts
        """
        id: str = field(default_factory=lambda: str(uuid.uuid4())[:8])
        name: str = "batch_job"
        shot_config: str = ""
        output_path: str = ""
        status: str = "pending"
        error: Optional[str] = None
        start_time: Optional[str] = None
        end_time: Optional[str] = None
        retry_count: int = 0

        def to_dict(self) -> Dict[str, Any]:
            return {
                "id": self.id,
                "name": self.name,
                "shot_config": self.shot_config,
                "output_path": self.output_path,
                "status": self.status,
                "error": self.error,
                "start_time": self.start_time,
                "end_time": self.end_time,
                "retry_count": self.retry_count,
            }

        @classmethod
        def from_dict(cls, data: Dict[str, Any]) -> "BatchJob":
            return cls(
                id=data.get("id", str(uuid.uuid4())[:8]),
                name=data.get("name", "batch_job"),
                shot_config=data.get("shot_config", ""),
                output_path=data.get("output_path", ""),
                status=data.get("status", "pending"),
                error=data.get("error"),
                start_time=data.get("start_time"),
                end_time=data.get("end_time"),
                retry_count=data.get("retry_count", 0),
            )


    @dataclass
    class BatchConfig:
        """
        Batch processing configuration.

        Attributes:
            workers: Number of parallel workers (default: CPU count - 1)
            resume_on_failure: Skip completed jobs on restart
            checkpoint_path: Path to checkpoint file
            max_retries: Maximum retry attempts per job
            timeout_seconds: Job timeout (0 = no timeout)
            continue_on_error: Continue batch if job fails
        """
        workers: int = 0  # 0 = auto-detect
        resume_on_failure: bool = True
        checkpoint_path: str = ".batch_checkpoint.json"
        max_retries: int = 3
        timeout_seconds: int = 0
        continue_on_error: bool = True

        def to_dict(self) -> Dict[str, Any]:
            return {
                "workers": self.workers,
                "resume_on_failure": self.resume_on_failure,
                "checkpoint_path": self.checkpoint_path,
                "max_retries": self.max_retries,
                "timeout_seconds": self.timeout_seconds,
                "continue_on_error": self.continue_on_error,
            }

        @classmethod
        def from_dict(cls, data: Dict[str, Any]) -> "BatchConfig":
            return cls(
                workers=data.get("workers", 0),
                resume_on_failure=data.get("resume_on_failure", True),
                checkpoint_path=data.get("checkpoint_path", ".batch_checkpoint.json"),
                max_retries=data.get("max_retries", 3),
                timeout_seconds=data.get("timeout_seconds", 0),
                continue_on_error=data.get("continue_on_error", True),
            )


    @dataclass
    class BatchResult:
        """
        Result of batch processing operation.

        Attributes:
            total_jobs: Total number of jobs in batch
            completed: Number of completed jobs
            failed: Number of failed jobs
            skipped: Number of skipped jobs (resume)
            duration_seconds: Total processing time
            jobs: List of job results
        """
        total_jobs: int = 0
        completed: int = 0
        failed: int = 0
        skipped: int = 0
        duration_seconds: float = 0.0
        jobs: List[BatchJob] = field(default_factory=list)

        def to_dict(self) -> Dict[str, Any]:
            return {
                "total_jobs": self.total_jobs,
                "completed": self.completed,
                "failed": self.failed,
                "skipped": self.skipped,
                "duration_seconds": self.duration_seconds,
                "jobs": [j.to_dict() for j in self.jobs],
            }
    ```

    Add `Optional` to the imports if not already present.
  </action>
  <verify>python -c "from lib.cinematic.tracking.types import BatchJob, BatchConfig, BatchResult; print('OK')"</verify>
  <done>BatchJob, BatchConfig, BatchResult dataclasses exist and are importable</done>
</task>

<task type="auto">
  <name>Create Batch Processing Module</name>
  <files>lib/cinematic/batch.py</files>
  <action>
    Create `lib/cinematic/batch.py` with the following implementation:

    ```python
    """
    Batch Processing System for Cinematic Rendering

    Provides parallel batch processing with:
    - Subprocess isolation for stability
    - Checkpoint-based resume on failure
    - Progress tracking and reporting
    - Support for tracking/render jobs

    Usage:
        from lib.cinematic.batch import BatchProcessor, BatchConfig, BatchJob

        # Configure batch
        config = BatchConfig(workers=4, resume_on_failure=True)

        # Create jobs
        jobs = [
            BatchJob(name="shot_01", shot_config="shots/shot_01.yaml", output_path="output/shot_01"),
            BatchJob(name="shot_02", shot_config="shots/shot_02.yaml", output_path="output/shot_02"),
        ]

        # Process batch
        processor = BatchProcessor(config)
        result = processor.process_batch(jobs)
    """

    from __future__ import annotations
    import json
    import subprocess
    import sys
    import time
    from concurrent.futures import ProcessPoolExecutor, as_completed
    from dataclasses import dataclass, field
    from datetime import datetime
    from multiprocessing import cpu_count
    from pathlib import Path
    from typing import Any, Callable, Dict, List, Optional, Tuple

    from .tracking.types import BatchJob, BatchConfig, BatchResult


    class BatchCheckpoint:
        """Manages checkpoint persistence for resume capability."""

        def __init__(self, checkpoint_path: str):
            self.checkpoint_path = Path(checkpoint_path)
            self.completed_ids: set = set()
            self._load()

        def _load(self):
            """Load checkpoint from disk."""
            if self.checkpoint_path.exists():
                try:
                    with open(self.checkpoint_path, "r") as f:
                        data = json.load(f)
                        self.completed_ids = set(data.get("completed", []))
                except (json.JSONDecodeError, KeyError):
                    self.completed_ids = set()

        def save(self):
            """Save checkpoint to disk."""
            self.checkpoint_path.parent.mkdir(parents=True, exist_ok=True)
            with open(self.checkpoint_path, "w") as f:
                json.dump({"completed": list(self.completed_ids)}, f, indent=2)

        def mark_completed(self, job_id: str):
            """Mark a job as completed."""
            self.completed_ids.add(job_id)
            self.save()

        def is_completed(self, job_id: str) -> bool:
            """Check if job is already completed."""
            return job_id in self.completed_ids

        def clear(self):
            """Clear checkpoint."""
            self.completed_ids = set()
            if self.checkpoint_path.exists():
                self.checkpoint_path.unlink()


    def run_job_subprocess(job: BatchJob, blender_path: str = "blender") -> Tuple[str, bool, Optional[str]]:
        """
        Run a batch job in a subprocess.

        This function runs in a separate process for isolation.

        Args:
            job: BatchJob to execute
            blender_path: Path to Blender executable

        Returns:
            Tuple of (job_id, success, error_message)
        """
        import traceback

        try:
            # For now, just simulate job execution
            # Real implementation would call Blender with shot config
            # Example:
            # cmd = [blender_path, "-b", "-P", "scripts/process_shot.py", "--", job.shot_config]
            # result = subprocess.run(cmd, capture_output=True, timeout=3600)

            # Simulate processing
            time.sleep(0.1)

            return (job.id, True, None)

        except Exception as e:
            return (job.id, False, f"{type(e).__name__}: {str(e)}\n{traceback.format_exc()}")


    class BatchProcessor:
        """
        Main batch processor with parallel execution and resume capability.

        Uses subprocess isolation to prevent crashes from affecting other jobs.
        """

        def __init__(self, config: Optional[BatchConfig] = None):
            """
            Initialize batch processor.

            Args:
                config: Batch configuration (uses defaults if not provided)
            """
            self.config = config or BatchConfig()
            self.checkpoint = BatchCheckpoint(self.config.checkpoint_path)
            self._cancelled = False

        def process_batch(self, jobs: List[BatchJob]) -> BatchResult:
            """
            Process a batch of jobs.

            Args:
                jobs: List of jobs to process

            Returns:
                BatchResult with processing summary
            """
            start_time = time.time()
            result = BatchResult(total_jobs=len(jobs))

            # Determine worker count
            workers = self.config.workers or max(1, cpu_count() - 1)

            # Filter completed jobs if resume enabled
            remaining_jobs = []
            for job in jobs:
                if self.config.resume_on_failure and self.checkpoint.is_completed(job.id):
                    job.status = "skipped"
                    job.end_time = datetime.now().isoformat()
                    result.skipped += 1
                    result.jobs.append(job)
                else:
                    remaining_jobs.append(job)

            if not remaining_jobs:
                result.duration_seconds = time.time() - start_time
                return result

            # Process jobs in parallel
            with ProcessPoolExecutor(max_workers=workers) as executor:
                futures = {
                    executor.submit(run_job_subprocess, job): job
                    for job in remaining_jobs
                }

                for future in as_completed(futures):
                    if self._cancelled:
                        executor.shutdown(wait=False, cancel_futures=True)
                        break

                    job = futures[future]
                    job.start_time = datetime.now().isoformat()
                    job.status = "running"

                    try:
                        job_id, success, error = future.result(
                            timeout=self.config.timeout_seconds if self.config.timeout_seconds > 0 else None
                        )

                        if success:
                            job.status = "completed"
                            result.completed += 1
                            self.checkpoint.mark_completed(job.id)
                        else:
                            job.status = "failed"
                            job.error = error
                            result.failed += 1

                    except subprocess.TimeoutExpired:
                        job.status = "failed"
                        job.error = "Job timed out"
                        result.failed += 1

                    except Exception as e:
                        job.status = "failed"
                        job.error = str(e)
                        result.failed += 1

                    finally:
                        job.end_time = datetime.now().isoformat()
                        result.jobs.append(job)

            result.duration_seconds = time.time() - start_time
            return result

        def cancel(self):
            """Cancel running batch."""
            self._cancelled = True

        def get_progress(self, jobs: List[BatchJob]) -> Dict[str, Any]:
            """
            Get current batch progress.

            Args:
                jobs: List of all jobs in batch

            Returns:
                Dict with progress information
            """
            total = len(jobs)
            completed = len([j for j in jobs if j.status == "completed"])
            failed = len([j for j in jobs if j.status == "failed"])
            running = len([j for j in jobs if j.status == "running"])
            pending = len([j for j in jobs if j.status == "pending"])

            return {
                "total": total,
                "completed": completed,
                "failed": failed,
                "running": running,
                "pending": pending,
                "progress_percent": (completed / total * 100) if total > 0 else 0,
            }

        def clear_checkpoint(self):
            """Clear checkpoint file."""
            self.checkpoint.clear()


    def create_batch_from_directory(
        shots_dir: str,
        output_dir: str,
        pattern: str = "*.yaml"
    ) -> List[BatchJob]:
        """
        Create batch jobs from a directory of shot configs.

        Args:
            shots_dir: Directory containing shot YAML files
            output_dir: Base output directory
            pattern: Glob pattern for shot files

        Returns:
            List of BatchJob instances
        """
        shots_path = Path(shots_dir)
        output_path = Path(output_dir)

        jobs = []
        for shot_file in sorted(shots_path.glob(pattern)):
            job = BatchJob(
                name=shot_file.stem,
                shot_config=str(shot_file),
                output_path=str(output_path / shot_file.stem),
            )
            jobs.append(job)

        return jobs


    def generate_batch_report(result: BatchResult, output_path: str) -> str:
        """
        Generate a batch processing report.

        Args:
            result: Batch processing result
            output_path: Path to write report

        Returns:
            Path to generated report
        """
        report_lines = [
            "# Batch Processing Report",
            "",
            f"**Generated:** {datetime.now().isoformat()}",
            f"**Duration:** {result.duration_seconds:.2f} seconds",
            "",
            "## Summary",
            "",
            f"| Metric | Count |",
            f"|--------|-------|",
            f"| Total Jobs | {result.total_jobs} |",
            f"| Completed | {result.completed} |",
            f"| Failed | {result.failed} |",
            f"| Skipped | {result.skipped} |",
            "",
            "## Job Details",
            "",
        ]

        for job in result.jobs:
            status_icon = {
                "completed": "[OK]",
                "failed": "[FAIL]",
                "skipped": "[SKIP]",
                "pending": "[WAIT]",
                "running": "[RUN]",
            }.get(job.status, "[??]")

            report_lines.append(f"### {status_icon} {job.name}")
            report_lines.append(f"- **Status:** {job.status}")
            report_lines.append(f"- **Config:** {job.shot_config}")
            report_lines.append(f"- **Output:** {job.output_path}")

            if job.error:
                report_lines.append(f"- **Error:** `{job.error}`")

            report_lines.append("")

        report_content = "\n".join(report_lines)

        Path(output_path).parent.mkdir(parents=True, exist_ok=True)
        with open(output_path, "w") as f:
            f.write(report_content)

        return output_path


    __all__ = [
        "BatchJob",
        "BatchConfig",
        "BatchResult",
        "BatchCheckpoint",
        "BatchProcessor",
        "run_job_subprocess",
        "create_batch_from_directory",
        "generate_batch_report",
    ]
    ```
  </action>
  <verify>python -c "from lib.cinematic.batch import BatchProcessor, BatchConfig, BatchJob, generate_batch_report; print('OK')"</verify>
  <done>BatchProcessor class with parallel execution, checkpoint resume, and report generation</done>
</task>

</tasks>

<verification>
- BatchJob, BatchConfig, BatchResult types importable from tracking.types
- BatchProcessor class with process_batch() method
- Checkpoint resume works across restarts
- generate_batch_report() creates markdown summary
</verification>

<success_criteria>
- Batch jobs can be configured and executed in parallel
- Resume from checkpoint skips completed jobs
- Batch reports summarize all results
- Subprocess isolation prevents crashes from affecting other jobs
</success_criteria>

<output>
After completion, create `.planning/phases/07.5-advanced-features/07.5-01-SUMMARY.md`
</output>
