# Phase 18.2-01: Projection Shader Nodes

**Phase**: 18.2 - Content Mapping Workflow
**Requirement**: REQ-PROJ-03
**Priority**: P0
**Est. Effort**: 1.5 days
**Depends on**: Phase 18.1 (Surface Calibration)

## Goal

Create camera projection shader nodes for content-to-surface mapping, adapted from Compify's node_groups.py.

## Background

From Compify's approach:
- Camera projection shader projects texture from camera POV
- Driven values: lens (focal length), sensor width, shift X/Y, aspect ratio
- Perspective division for projection coordinates

We need to adapt this for physical projectors with throw ratio instead of focal length.

## Tasks

### 1. Create Shader Types (`lib/cinematic/projection/physical/shaders/types.py`)

```python
from dataclasses import dataclass, field
from typing import Optional, Tuple
from enum import Enum

class ProjectionMode(Enum):
    """Content projection mode."""
    CAMERA = "camera"           # Project from camera/projector POV
    UV = "uv"                   # Use existing UV coordinates
    TRIPLANAR = "triplanar"     # Triplanar projection

@dataclass
class ProjectionShaderConfig:
    """Configuration for projector shader."""
    # Projector parameters
    throw_ratio: float = 1.0
    sensor_width: float = 36.0
    resolution_x: int = 1920
    resolution_y: int = 1080
    shift_x: float = 0.0
    shift_y: float = 0.0

    # Projection settings
    mode: ProjectionMode = ProjectionMode.CAMERA
    blend_mode: str = "mix"     # mix, add, multiply, overlay
    intensity: float = 1.0

    # Content
    content_image: Optional[str] = None

    # Advanced
    use_mipmap: bool = True
    filter_type: str = "Linear"  # Linear, Closest, Cubic
    extension: str = "Repeat"    # Repeat, Extend, Clip

@dataclass
class ProjectionShaderResult:
    """Result of shader creation."""
    material: bpy.types.Material
    node_group: bpy.types.NodeGroup
    texture_node: bpy.types.ShaderNodeTexImage
    projection_node: bpy.types.ShaderNodeGroup
```

### 2. Create Projection Node Group (`lib/cinematic/projection/physical/shaders/projector_nodes.py`)

```python
import bpy
from mathutils import Vector
from typing import Optional

def ensure_projector_projection_group() -> bpy.types.NodeGroup:
    """
    Create or retrieve the projector projection node group.

    This node group computes UV coordinates from projector perspective,
    adapted from Compify's camera projection shader.

    Inputs:
        - Throw Ratio
        - Resolution X
        - Resolution Y
        - Shift X
        - Shift Y
        - Projector Position
        - Projector Rotation

    Outputs:
        - UV: UV coordinates for texture sampling
        - Valid: Whether point is in projector frustum
    """
    group_name = "Projector_Projection"

    # Check if exists
    if group_name in bpy.data.node_groups:
        return bpy.data.node_groups[group_name]

    # Create group
    group = bpy.data.node_groups.new(group_name, 'ShaderNodeTree')

    # Create inputs
    inputs = group.inputs
    inputs.new('NodeSocketFloat', 'Throw Ratio').default_value = 1.0
    inputs.new('NodeSocketInt', 'Resolution X').default_value = 1920
    inputs.new('NodeSocketInt', 'Resolution Y').default_value = 1080
    inputs.new('NodeSocketFloat', 'Shift X').default_value = 0.0
    inputs.new('NodeSocketFloat', 'Shift Y').default_value = 0.0
    inputs.new('NodeSocketVector', 'Projector Position').default_value = (0, 0, 0)
    inputs.new('NodeSocketVector', 'Projector Rotation').default_value = (0, 0, 0)

    # Create outputs
    outputs = group.outputs
    outputs.new('NodeSocketVector', 'UV')
    outputs.new('NodeSocketFloat', 'Valid')

    # Build node tree
    # 1. Get geometry position (world space)
    # 2. Transform to projector space (inverse of projector transform)
    # 3. Perspective division to get UV
    # 4. Apply lens shift
    # 5. Output UV and validity check

    # ... (detailed node creation)

    return group


def create_projector_material(
    config: ProjectionShaderConfig,
    projector_object: bpy.types.Object
) -> ProjectionShaderResult:
    """
    Create material with projector projection shader.

    Args:
        config: Shader configuration
        projector_object: Blender camera object representing projector

    Returns:
        ProjectionShaderResult with created nodes
    """
    # Create material
    mat = bpy.data.materials.new(name="Projector_Material")
    mat.use_nodes = True
    nodes = mat.node_tree.nodes
    links = mat.node_tree.links

    # Clear default nodes
    nodes.clear()

    # Create output node
    output = nodes.new('ShaderNodeOutputMaterial')
    output.location = (600, 0)

    # Create emission shader (we want pure color output for projection)
    emission = nodes.new('ShaderNodeEmission')
    emission.location = (400, 0)

    # Create texture node
    tex = nodes.new('ShaderNodeTexImage')
    if config.content_image:
        tex.image = bpy.data.images.load(config.content_image)
    tex.location = (0, 0)

    # Create projection node group
    proj_group = ensure_projector_projection_group()
    proj_node = nodes.new('ShaderNodeGroup')
    proj_node.node_tree = proj_group
    proj_node.location = (-200, 0)

    # Set default values
    proj_node.inputs['Throw Ratio'].default_value = config.throw_ratio
    proj_node.inputs['Resolution X'].default_value = config.resolution_x
    proj_node.inputs['Resolution Y'].default_value = config.resolution_y
    proj_node.inputs['Shift X'].default_value = config.shift_x
    proj_node.inputs['Shift Y'].default_value = config.shift_y

    # Link projection UV to texture
    links.new(proj_node.outputs['UV'], tex.inputs['Vector'])

    # Link texture to emission
    links.new(tex.outputs['Color'], emission.inputs['Color'])

    # Link emission to output
    links.new(emission.outputs['Emission'], output.inputs['Surface'])

    return ProjectionShaderResult(
        material=mat,
        node_group=proj_group,
        texture_node=tex,
        projection_node=proj_node
    )
```

### 3. Create Proxy Geometry Generator (`lib/cinematic/projection/physical/shaders/proxy_geometry.py`)

```python
from dataclasses import dataclass
from typing import List, Optional
import bpy
from mathutils import Vector

@dataclass
class ProxyGeometryConfig:
    """Configuration for proxy geometry generation."""
    subdivisions: int = 2
    margin: float = 0.1        # Margin around projection area
    optimize_uv: bool = True   # Optimize UV layout for projection

def create_proxy_geometry_for_surface(
    calibration: SurfaceCalibration,
    config: ProxyGeometryConfig = ProxyGeometryConfig()
) -> bpy.types.Object:
    """
    Create UV-mapped proxy geometry for projection surface.

    The proxy geometry is a simplified mesh that matches the projection
    surface, optimized for UV projection from the projector.

    Args:
        calibration: Surface calibration data
        config: Proxy geometry configuration

    Returns:
        Blender mesh object for proxy geometry
    """
    # For 3-point planar calibration, create a simple plane
    if calibration.calibration_type == CalibrationType.THREE_POINT:
        return create_planar_proxy(calibration, config)

    # For 4-point DLT, potentially create more complex geometry
    elif calibration.calibration_type == CalibrationType.FOUR_POINT_DLT:
        return create_multi_surface_proxy(calibration, config)


def create_planar_proxy(
    calibration: SurfaceCalibration,
    config: ProxyGeometryConfig
) -> bpy.types.Object:
    """Create planar proxy geometry from 3-point calibration."""
    # Get world positions
    p1 = Vector(calibration.points[0].world_position)
    p2 = Vector(calibration.points[1].world_position)
    p3 = Vector(calibration.points[2].world_position)

    # Compute corners of rectangle
    # (4th corner computed from 3 points)
    v1 = p2 - p1  # Bottom edge
    v2 = p3 - p1  # Left edge
    p4 = p1 + v1 + v2  # Top-right corner

    # Create mesh
    mesh = bpy.data.meshes.new("Projection_Proxy")
    obj = bpy.data.objects.new("Projection_Proxy", mesh)

    # Create vertices
    verts = [p1, p2, p4, p3]
    faces = [(0, 1, 2, 3)]

    mesh.from_pydata(verts, [], faces)

    # UV unwrap (simple projection)
    # UV coordinates match projector UV from calibration
    uv_layer = mesh.uv_layers.new()
    for i, point in enumerate(calibration.points):
        uv_layer.data[i].uv = point.projector_uv
    # 4th vertex UV
    uv_layer.data[3].uv = (
        calibration.points[1].projector_uv[0],
        calibration.points[2].projector_uv[1]
    )

    # Link to scene
    bpy.context.collection.objects.link(obj)

    return obj


def create_multi_surface_proxy(
    calibration: SurfaceCalibration,
    config: ProxyGeometryConfig
) -> bpy.types.Object:
    """Create multi-surface proxy geometry from 4-point DLT calibration."""
    # Create convex hull of calibration points
    # More complex geometry for non-planar surfaces
    pass
```

### 4. Create Content Mapper (`lib/cinematic/projection/physical/shaders/content_mapper.py`)

```python
from typing import Optional
import bpy

class ContentMapper:
    """Map content textures to projection surfaces."""

    def __init__(self, projector_profile: ProjectorProfile):
        self.profile = projector_profile
        self.shader_config = ProjectionShaderConfig(
            throw_ratio=projector_profile.throw_ratio,
            resolution_x=projector_profile.native_resolution[0],
            resolution_y=projector_profile.native_resolution[1],
            shift_x=projector_profile.lens_shift_horizontal,
            shift_y=projector_profile.lens_shift_vertical,
        )

    def map_content_to_surface(
        self,
        content_path: str,
        surface_object: bpy.types.Object,
        projector_object: bpy.types.Object,
        calibration: SurfaceCalibration
    ) -> bpy.types.Material:
        """
        Map content image/video to surface via projector projection.

        Args:
            content_path: Path to content image/video
            surface_object: Target surface mesh
            projector_object: Projector camera object
            calibration: Surface calibration data

        Returns:
            Material with projection shader applied
        """
        # Load content
        if content_path.endswith(('.png', '.jpg', '.jpeg', '.exr')):
            content = bpy.data.images.load(content_path)
        elif content_path.endswith(('.mp4', '.mov', '.avi')):
            content = bpy.data.movieclips.load(content_path)
        else:
            raise ValueError(f"Unsupported content format: {content_path}")

        # Create shader
        self.shader_config.content_image = content_path
        result = create_projector_material(self.shader_config, projector_object)

        # Apply to surface
        if surface_object.data.materials:
            surface_object.data.materials[0] = result.material
        else:
            surface_object.data.materials.append(result.material)

        return result.material

    def update_content(self, material: bpy.types.Material, new_content_path: str):
        """Update content texture in existing material."""
        # Find texture node and update image
        pass

    def set_projection_intensity(self, material: bpy.types.Material, intensity: float):
        """Set projection intensity (for blending)."""
        pass
```

## Deliverables

```
lib/cinematic/projection/physical/shaders/
├── __init__.py
├── types.py               # ProjectionShaderConfig, ProjectionMode
├── projector_nodes.py     # Node group creation
├── proxy_geometry.py      # UV-mapped proxy geometry
└── content_mapper.py      # Content-to-surface mapping
```

## Tests

- `test_shader_types.py`: Shader configuration tests
- `test_projector_nodes.py`: Node group creation tests
- `test_proxy_geometry.py`: Proxy geometry generation tests
- `test_content_mapper.py`: Content mapping workflow tests

## Acceptance Criteria

- [ ] Projection shader node group creates correctly
- [ ] Shader projects content from projector POV
- [ ] Proxy geometry generates with correct UVs
- [ ] Content mapper applies texture to surface
- [ ] 20+ unit tests passing
