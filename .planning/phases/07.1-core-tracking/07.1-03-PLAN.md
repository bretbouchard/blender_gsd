---
phase: 07.1-core-tracking
plan: 03
type: execute
wave: 3
depends_on: ["07.1-02"]
files_modified:
  - lib/cinematic/tracking/camera_solver.py
  - configs/cinematic/tracking/solver_settings.yaml
autonomous: true
user_setup: []

must_haves:
  truths:
    - "Camera solve produces animated camera from tracked footage"
    - "Blender's libmv solver is accessible via Python API"
    - "Focal length can be refined during solve"
    - "Solve quality report shows reprojection error"
    - "Solved camera has keyframed animation in Blender"
  artifacts:
    - path: "lib/cinematic/tracking/camera_solver.py"
      provides: "Camera solver implementation (REQ-TRACK-SOLVE)"
      min_lines: 350
      exports: ["solve_camera", "create_camera_from_solve", "get_solve_report", "CameraSolver"]
    - path: "configs/cinematic/tracking/solver_settings.yaml"
      provides: "Solver configuration presets"
      contains: "solver_presets:"
  key_links:
    - from: "lib/cinematic/tracking/camera_solver.py"
      to: "bpy.ops.clip.solve_camera"
      via: "libmv integration"
      pattern: "solve_camera"
    - from: "lib/cinematic/tracking/camera_solver.py"
      to: "lib/cinematic/tracking/types.py"
      via: "SolveData, SolveReport"
      pattern: "SolveData|SolveReport"
    - from: "lib/cinematic/tracking/camera_solver.py"
      to: "lib/cinematic/camera.py"
      via: "create_camera integration"
      pattern: "create_camera"
---

<objective>
Implement camera solver with libmv integration for solving camera motion from tracked points and creating animated Blender cameras.

Purpose: Provide complete REQ-TRACK-SOLVE implementation using Blender's libmv solver with auto keyframe selection, focal length refinement, and camera creation.
Output: camera_solver.py with solve_camera, create_camera_from_solve, and CameraSolver class; updated solver_settings.yaml with solver presets.
</objective>

<execution_context>
@/Users/bretbouchard/.claude/get-shit-done/workflows/execute-plan.md
@/Users/bretbouchard/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/07.1-core-tracking/07.1-RESEARCH.md

# Reference Wave 2 point tracking
@.planning/phases/07.1-core-tracking/07.1-02-PLAN.md

# Reference existing types and modules
@lib/cinematic/tracking/types.py
@lib/cinematic/tracking/context.py
@lib/cinematic/camera.py
</context>

<tasks>

<task type="auto">
  <name>Create camera solver module</name>
  <files>lib/cinematic/tracking/camera_solver.py</files>
  <action>
Create camera_solver.py implementing REQ-TRACK-SOLVE using Blender's libmv integration.

Key implementation requirements:

1. Camera Solver:
```python
"""
Camera Solver Module

Provides camera solving functionality using Blender's libmv integration.
Extracts 3D camera motion from 2D point tracks.

Key Functions:
- solve_camera: Run camera solver on tracked footage
- create_camera_from_solve: Create Blender camera from solve results
- get_solve_report: Generate solve quality report
"""

from __future__ import annotations
from dataclasses import dataclass, field
from typing import Dict, Any, Optional, Tuple, List
from datetime import datetime
import math

try:
    import bpy
    from mathutils import Matrix, Euler
    BLENDER_AVAILABLE = True
except ImportError:
    bpy = None
    BLENDER_AVAILABLE = False

from .context import tracking_context
from .types import SolveData, SolveReport, TrackData


def solve_camera(
    clip,
    preset: str = "balanced",
    refine_focal_length: bool = True,
    refine_distortion: str = "k1_only",
    keyframes: Optional[Tuple[int, int]] = None,
) -> Dict[str, Any]:
    """
    Solve camera motion from tracked markers.

    Uses Blender's libmv solver via bpy.ops.clip.solve_camera.

    Args:
        clip: MovieClip with tracked markers
        preset: Solver preset (affects quality thresholds)
        refine_focal_length: Allow solver to refine focal length
        refine_distortion: Distortion refinement mode (none, k1_only, k1_k2)
        keyframes: Optional (start, end) keyframe tuple. If None, auto-selects.

    Returns:
        Dict with solve results:
        - success: Whether solve succeeded
        - average_error: Average reprojection error in pixels
        - camera_count: Number of solved camera positions
        - reconstruction: Reference to reconstruction object

    Raises:
        RuntimeError: If Blender not available or solve fails
    """
    if not BLENDER_AVAILABLE:
        raise RuntimeError("Blender not available")

    # Configure tracking camera settings
    tracking_cam = clip.tracking.camera

    # Set refinement options
    if refine_focal_length:
        tracking_cam.focal_length = tracking_cam.focal_length  # Keep initial

    # Set distortion refinement mode
    # Note: Blender 4.x uses different settings than earlier versions
    # The libmv solver handles this internally

    # Run solve
    with tracking_context(clip) as ctx:
        result = bpy.ops.clip.solve_camera(ctx)

    if result != {'FINISHED'}:
        return {
            "success": False,
            "average_error": float('inf'),
            "camera_count": 0,
            "error": "Solver failed to run",
        }

    # Get reconstruction results
    reconstruction = clip.tracking.reconstruction

    if not reconstruction.is_valid:
        return {
            "success": False,
            "average_error": float('inf'),
            "camera_count": 0,
            "error": "Reconstruction is not valid",
        }

    return {
        "success": True,
        "average_error": reconstruction.average_error,
        "camera_count": len(reconstruction.cameras),
        "reconstruction": reconstruction,
    }
```

2. Camera Creation from Solve:
```python
def create_camera_from_solve(
    clip,
    camera_name: str = "Solved Camera",
    set_active: bool = True,
    keyframe_mode: str = "all_frames",
) -> 'bpy.types.Object':
    """
    Create Blender camera from solved tracking data.

    Creates a new camera object with animation keyframes matching
    the solved camera motion.

    Args:
        clip: MovieClip with valid reconstruction
        camera_name: Name for the new camera object
        set_active: Set as scene active camera
        keyframe_mode: Keyframe mode (all_frames, keyframes_only)

    Returns:
        Created camera object

    Raises:
        RuntimeError: If Blender not available or reconstruction invalid
        ValueError: If reconstruction is not valid
    """
    if not BLENDER_AVAILABLE:
        raise RuntimeError("Blender not available")

    reconstruction = clip.tracking.reconstruction

    if not reconstruction.is_valid:
        raise ValueError("Reconstruction is not valid - solve camera first")

    # Get tracking camera settings
    tracking_cam = clip.tracking.camera

    # Create camera data
    cam_data = bpy.data.cameras.new(camera_name)
    cam_obj = bpy.data.objects.new(camera_name, cam_data)

    # Link to scene
    bpy.context.collection.objects.link(cam_obj)

    # Set camera properties from tracking camera
    cam_data.lens = tracking_cam.focal_length
    cam_data.sensor_width = tracking_cam.sensor_width
    cam_data.sensor_fit = 'HORIZONTAL'

    # Animate camera from reconstruction
    for recon_cam in reconstruction.cameras:
        frame = recon_cam.frame

        # Set position
        cam_obj.location = recon_cam.location
        cam_obj.keyframe_insert('location', frame=frame)

        # Set rotation
        # Note: recon_cam.rotation is a Matrix, convert to Euler
        if hasattr(recon_cam, 'rotation'):
            rotation_matrix = recon_cam.rotation
            cam_obj.rotation_euler = rotation_matrix.to_euler()
        else:
            # Fallback for older Blender versions
            cam_obj.rotation_euler = Euler((0, 0, 0))

        cam_obj.keyframe_insert('rotation_euler', frame=frame)

    # Set as active camera if requested
    if set_active:
        bpy.context.scene.camera = cam_obj

    return cam_obj


def apply_camera_from_solve(
    clip,
    target_camera: 'bpy.types.Object',
    preserve_existing_keys: bool = False,
) -> None:
    """
    Apply solve data to existing camera.

    Args:
        clip: MovieClip with valid reconstruction
        target_camera: Camera object to animate
        preserve_existing_keys: Keep existing keyframes outside solve range
    """
    if not BLENDER_AVAILABLE:
        raise RuntimeError("Blender not available")

    reconstruction = clip.tracking.reconstruction

    if not reconstruction.is_valid:
        raise ValueError("Reconstruction is not valid")

    # Store existing keyframes if preserving
    existing_keys = {}
    if preserve_existing_keys:
        for fcu in target_camera.animation_data.action.fcurves:
            existing_keys[fcu.data_path] = [kf.co[0] for kf in fcu.keyframe_points]

    tracking_cam = clip.tracking.camera

    # Update focal length
    if target_camera.data:
        target_camera.data.lens = tracking_cam.focal_length
        target_camera.data.sensor_width = tracking_cam.sensor_width

    # Apply animation
    for recon_cam in reconstruction.cameras:
        frame = recon_cam.frame

        target_camera.location = recon_cam.location
        target_camera.keyframe_insert('location', frame=frame)

        if hasattr(recon_cam, 'rotation'):
            target_camera.rotation_euler = recon_cam.rotation.to_euler()
        target_camera.keyframe_insert('rotation_euler', frame=frame)
```

3. Solve Report Generation:
```python
def get_solve_report(clip) -> SolveReport:
    """
    Generate solve quality report from reconstruction.

    Args:
        clip: MovieClip with reconstruction

    Returns:
        SolveReport with quality metrics
    """
    if not BLENDER_AVAILABLE:
        raise RuntimeError("Blender not available")

    reconstruction = clip.tracking.reconstruction

    avg_error = reconstruction.average_error if reconstruction.is_valid else float('inf')

    # Determine quality level
    if avg_error < 0.3:
        quality_level = "excellent"
        confidence = 0.95
    elif avg_error < 0.5:
        quality_level = "good"
        confidence = 0.85
    elif avg_error < 1.0:
        quality_level = "acceptable"
        confidence = 0.70
    else:
        quality_level = "poor"
        confidence = 0.50

    return SolveReport(
        reprojection_error_avg=avg_error,
        reprojection_error_max=avg_error * 2.0,  # Estimate max
        tracks_used=len([t for t in clip.tracking.tracks if not t.mute]),
        frames_solved=len(reconstruction.cameras) if reconstruction.is_valid else 0,
        confidence_score=confidence,
        quality_level=quality_level,
    )


def export_solve_data(clip, output_path: str) -> None:
    """
    Export solve data to YAML for external use.

    Args:
        clip: MovieClip with valid reconstruction
        output_path: Path to save YAML file
    """
    if not BLENDER_AVAILABLE:
        raise RuntimeError("Blender not available")

    reconstruction = clip.tracking.reconstruction

    if not reconstruction.is_valid:
        raise ValueError("Reconstruction is not valid")

    tracking_cam = clip.tracking.camera

    # Build solve data
    camera_transforms = {}
    for recon_cam in reconstruction.cameras:
        frame = recon_cam.frame
        loc = recon_cam.location

        if hasattr(recon_cam, 'rotation'):
            rot = recon_cam.rotation.to_euler()
            camera_transforms[frame] = (
                loc[0], loc[1], loc[2],
                rot[0], rot[1], rot[2]
            )
        else:
            camera_transforms[frame] = (
                loc[0], loc[1], loc[2],
                0.0, 0.0, 0.0
            )

    solve_data = SolveData(
        name=clip.name,
        frame_range=(clip.frame_start, clip.frame_start + clip.frame_duration - 1),
        focal_length=tracking_cam.focal_length,
        sensor_width=tracking_cam.sensor_width,
        camera_transforms=camera_transforms,
        coordinate_system="z_up",
        solved_at=datetime.utcnow().isoformat(),
    )

    # Write to file
    import yaml
    from pathlib import Path

    Path(output_path).parent.mkdir(parents=True, exist_ok=True)

    with open(output_path, 'w') as f:
        yaml.dump(solve_data.to_dict(), f, default_flow_style=False)
```

4. CameraSolver Class:
```python
class CameraSolver:
    """
    High-level camera solving workflow manager.

    Provides simplified interface for complete solve workflow.

    Usage:
        solver = CameraSolver(clip)
        result = solver.solve(refine_focal_length=True)
        if result['success']:
            camera = solver.create_camera("Tracked Camera")
            report = solver.get_report()
            print(f"Average error: {report.reprojection_error_avg:.2f}px")
    """

    def __init__(self, clip):
        """Initialize solver with clip."""
        self.clip = clip
        self._solve_result: Optional[Dict[str, Any]] = None

    def solve(self, **kwargs) -> Dict[str, Any]:
        """Run camera solver."""
        self._solve_result = solve_camera(self.clip, **kwargs)
        return self._solve_result

    def create_camera(self, name: str = "Solved Camera", **kwargs) -> 'bpy.types.Object':
        """Create Blender camera from solve."""
        if not self._solve_result or not self._solve_result.get('success'):
            raise RuntimeError("Solve not successful - call solve() first")
        return create_camera_from_solve(self.clip, camera_name=name, **kwargs)

    def get_report(self) -> SolveReport:
        """Get solve quality report."""
        return get_solve_report(self.clip)

    def export(self, output_path: str) -> None:
        """Export solve data to YAML."""
        export_solve_data(self.clip, output_path)

    @property
    def is_solved(self) -> bool:
        """Check if reconstruction is valid."""
        if not BLENDER_AVAILABLE:
            return False
        return self.clip.tracking.reconstruction.is_valid

    @property
    def average_error(self) -> float:
        """Get average reprojection error."""
        if not BLENDER_AVAILABLE:
            return float('inf')
        return self.clip.tracking.reconstruction.average_error
```

5. Include proper error handling and coordinate system conversion notes.
</action>
  <verify>
python3 -c "
from lib.cinematic.tracking.camera_solver import (
    solve_camera, create_camera_from_solve,
    get_solve_report, export_solve_data,
    CameraSolver, BLENDER_AVAILABLE
)

print(f'BLENDER_AVAILABLE: {BLENDER_AVAILABLE}')
print('Camera solver module imports work')

# Verify function signatures
import inspect
print(f'solve_camera signature: {inspect.signature(solve_camera)}')
print(f'create_camera_from_solve signature: {inspect.signature(create_camera_from_solve)}')
print(f'CameraSolver methods: {[m for m in dir(CameraSolver) if not m.startswith(\"_\")]}')
"
  </verify>
  <done>
- lib/cinematic/tracking/camera_solver.py created with REQ-TRACK-SOLVE implementation
- solve_camera() runs libmv solver via bpy.ops.clip.solve_camera
- create_camera_from_solve() creates animated Blender camera
- get_solve_report() generates quality metrics
- CameraSolver class provides high-level workflow
- export_solve_data() saves solve to YAML
  </done>
</task>

<task type="auto">
  <name>Update solver settings YAML</name>
  <files>configs/cinematic/tracking/solver_settings.yaml</files>
  <action>
Update solver_settings.yaml with comprehensive solver configuration presets.

The YAML should include:

```yaml
# Camera Solver Settings
# Configures libmv camera solver parameters

solver_presets:
  # High accuracy (slower)
  high_accuracy:
    description: "Maximum accuracy for critical shots"
    refinement:
      refine_focal_length: true
      refine_principal_point: false
      refine_radial_distortion: "k1_only"  # none, k1_only, k1_k2
    motion:
      type: "perspective"  # perspective, affine
    quality:
      max_reprojection_error: 0.5  # Pixels
      min_tracks_per_frame: 12
    keyframes:
      auto_select: true
      min_separation: 10  # Frames between keyframes

  # Balanced (default)
  balanced:
    description: "Good trade-off between speed and accuracy"
    refinement:
      refine_focal_length: true
      refine_principal_point: false
      refine_radial_distortion: "k1_only"
    motion:
      type: "perspective"
    quality:
      max_reprojection_error: 1.0
      min_tracks_per_frame: 8
    keyframes:
      auto_select: true
      min_separation: 5

  # Fast solve
  fast:
    description: "Quick solve for preview"
    refinement:
      refine_focal_length: false
      refine_principal_point: false
      refine_radial_distortion: "none"
    motion:
      type: "affine"
    quality:
      max_reprojection_error: 2.0
      min_tracks_per_frame: 6
    keyframes:
      auto_select: true
      min_separation: 3

  # Architectural
  architectural:
    description: "Optimized for buildings and interiors"
    refinement:
      refine_focal_length: true
      refine_principal_point: true
      refine_radial_distortion: "k1_k2"
    motion:
      type: "perspective"
    quality:
      max_reprojection_error: 0.7
      min_tracks_per_frame: 10
    keyframes:
      auto_select: true
      min_separation: 8

# Quality thresholds for solve assessment
quality_thresholds:
  excellent:
    reprojection_error_avg: 0.3
    confidence: 0.95
  good:
    reprojection_error_avg: 0.5
    confidence: 0.85
  acceptable:
    reprojection_error_avg: 1.0
    confidence: 0.70
  poor:
    reprojection_error_avg: 2.0
    confidence: 0.50

# Distortion models
distortion_models:
  # No distortion refinement
  none:
    description: "Fixed distortion, no refinement"

  # Simple radial distortion (k1 only)
  k1_only:
    description: "Refine k1 coefficient only"
    parameters: ["k1"]

  # Radial distortion (k1, k2)
  k1_k2:
    description: "Refine k1 and k2 coefficients"
    parameters: ["k1", "k2"]
```

If the file already exists from Phase 7.0, merge these settings into it.
</action>
  <verify>
python3 -c "
import yaml
from pathlib import Path

settings_file = Path('configs/cinematic/tracking/solver_settings.yaml')
if settings_file.exists():
    with open(settings_file, 'r') as f:
        data = yaml.safe_load(f)

    presets = data.get('solver_presets', {})
    print(f'Solver presets defined: {list(presets.keys())}')

    # Check quality thresholds
    thresholds = data.get('quality_thresholds', {})
    print(f'Quality thresholds: {list(thresholds.keys())}')
else:
    print('Settings file not found (will be created)')
"
  </verify>
  <done>
- solver_settings.yaml contains comprehensive solver presets
- Quality thresholds for assessment defined
- Distortion models documented
- All presets have refinement, motion, quality, and keyframe sections
  </done>
</task>

</tasks>

<verification>
# Phase-level verification
1. camera_solver.py imports without errors
2. solve_camera() function accessible
3. create_camera_from_solve() function accessible
4. CameraSolver class provides workflow interface
5. solver_settings.yaml has required presets
</verification>

<success_criteria>
- lib/cinematic/tracking/camera_solver.py implements REQ-TRACK-SOLVE
- libmv integration via bpy.ops.clip.solve_camera
- Camera creation with animation keyframes
- Solve quality reporting with reprojection error
- solver_settings.yaml provides configuration presets
</success_criteria>

<output>
After completion, create `.planning/phases/07.1-core-tracking/07.1-03-SUMMARY.md`
</output>
