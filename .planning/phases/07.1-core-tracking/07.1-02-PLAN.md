---
phase: 07.1-core-tracking
plan: 02
type: execute
wave: 2
depends_on: ["07.1-01"]
files_modified:
  - lib/cinematic/tracking/point_tracker.py
  - lib/cinematic/tracking/quality.py
autonomous: true
user_setup: []

must_haves:
  truths:
    - "Features are automatically detected in footage"
    - "Tracks follow features through frame range using KLT optical flow"
    - "Tracks can be added, deleted, filtered, and configured"
    - "Track quality analysis identifies problematic tracks"
    - "Low-quality tracks are cleaned before solving"
  artifacts:
    - path: "lib/cinematic/tracking/point_tracker.py"
      provides: "Point tracking implementation (REQ-TRACK-POINT)"
      min_lines: 300
      exports: ["detect_features", "track_markers", "add_track", "delete_track", "configure_track", "PointTracker"]
    - path: "lib/cinematic/tracking/quality.py"
      provides: "Track quality analysis and filtering"
      min_lines: 150
      exports: ["analyze_track_quality", "clean_low_quality_tracks", "filter_tracks_by_correlation", "get_track_quality_report"]
  key_links:
    - from: "lib/cinematic/tracking/point_tracker.py"
      to: "lib/cinematic/tracking/context.py"
      via: "tracking_context manager"
      pattern: "with tracking_context"
    - from: "lib/cinematic/tracking/point_tracker.py"
      to: "lib/cinematic/tracking/presets.py"
      via: "get_tracking_preset"
      pattern: "get_tracking_preset|get_detection_params"
    - from: "lib/cinematic/tracking/quality.py"
      to: "bpy.ops.clip.clean_tracks"
      via: "track quality filtering"
      pattern: "clean_tracks"
---

<objective>
Implement point tracking system with feature detection, KLT optical flow tracking, track management, and quality analysis.

Purpose: Provide complete REQ-TRACK-POINT implementation using Blender's built-in tracking API with proper context management.
Output: point_tracker.py with feature detection and tracking, quality.py with track quality analysis and filtering.
</objective>

<execution_context>
@/Users/bretbouchard/.claude/get-shit-done/workflows/execute-plan.md
@/Users/bretbouchard/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/07.1-core-tracking/07.1-RESEARCH.md

# Reference Wave 1 foundation
@.planning/phases/07.1-core-tracking/07.1-01-PLAN.md

# Reference existing tracking types
@lib/cinematic/tracking/types.py
@lib/cinematic/tracking/context.py
@lib/cinematic/tracking/presets.py
</context>

<tasks>

<task type="auto">
  <name>Create point tracker module</name>
  <files>lib/cinematic/tracking/point_tracker.py</files>
  <action>
Create point_tracker.py implementing REQ-TRACK-POINT using Blender's built-in tracking API.

Key implementation requirements:

1. Feature Detection:
```python
def detect_features(
    clip,
    preset: str = "balanced",
    threshold: Optional[float] = None,
    margin: Optional[int] = None,
    min_distance: Optional[int] = None,
) -> int:
    """
    Detect trackable features in the current frame.

    Uses Blender's built-in feature detection via bpy.ops.clip.detect_features.
    Requires active Clip Editor context.

    Args:
        clip: MovieClip to detect features in
        preset: Preset name for default parameters
        threshold: Override detection threshold (0-1, lower = more features)
        margin: Override margin from edges in pixels
        min_distance: Override minimum distance between features

    Returns:
        Number of tracks created

    Raises:
        RuntimeError: If Blender not available or context setup fails
    """
    if not BLENDER_AVAILABLE:
        raise RuntimeError("Blender not available")

    # Get preset parameters
    params = get_detection_params(preset)

    # Apply overrides
    threshold = threshold if threshold is not None else params.get("threshold", 0.5)
    margin = margin if margin is not None else params.get("margin", 16)
    min_distance = min_distance if min_distance is not None else params.get("min_distance", 8)

    with tracking_context(clip) as ctx:
        result = bpy.ops.clip.detect_features(
            ctx,
            threshold=threshold,
            margin=margin,
            min_distance=min_distance,
        )

    return len(clip.tracking.tracks)
```

2. Marker Tracking:
```python
def track_markers(
    clip,
    frame_start: Optional[int] = None,
    frame_end: Optional[int] = None,
    backwards: bool = False,
    sequence: bool = True,
) -> Dict[str, Any]:
    """
    Track all markers through frame range using KLT optical flow.

    Args:
        clip: MovieClip with tracks
        frame_start: Starting frame (default: clip.frame_start)
        frame_end: Ending frame (default: clip.frame_start + clip.frame_duration)
        backwards: Track backwards from current frame
        sequence: Track entire sequence (True) or single frame (False)

    Returns:
        Dict with tracking results:
        - tracks_count: Number of tracks processed
        - frames_processed: Number of frames tracked
        - status: "completed" or "partial"
    """
    if not BLENDER_AVAILABLE:
        raise RuntimeError("Blender not available")

    # Set frame range
    if frame_start is None:
        frame_start = clip.frame_start
    if frame_end is None:
        frame_end = clip.frame_start + clip.frame_duration

    scene = bpy.context.scene
    original_frame = scene.frame_current

    try:
        with tracking_context(clip) as ctx:
            if sequence:
                # Track entire sequence
                result = bpy.ops.clip.track_markers(
                    ctx,
                    backwards=backwards,
                    sequence=True,
                )
            else:
                # Track frame by frame for more control
                frames_processed = 0
                frame_range = range(frame_start, frame_end + 1)
                if backwards:
                    frame_range = range(frame_end, frame_start - 1, -1)

                for frame in frame_range:
                    scene.frame_set(frame)
                    bpy.ops.clip.track_markers(
                        ctx,
                        backwards=backwards,
                        sequence=False,
                    )
                    frames_processed += 1

        return {
            "tracks_count": len(clip.tracking.tracks),
            "frames_processed": abs(frame_end - frame_start) + 1,
            "status": "completed",
        }

    finally:
        scene.frame_set(original_frame)
```

3. Track Management:
```python
def add_track(
    clip,
    frame: int,
    position: Tuple[float, float],
    name: Optional[str] = None,
) -> 'bpy.types.MovieTrackingTrack':
    """
    Add a new track at specified position.

    Args:
        clip: MovieClip to add track to
        frame: Frame number for initial marker
        position: (x, y) normalized position (0-1)
        name: Optional track name

    Returns:
        Created track
    """
    if not BLENDER_AVAILABLE:
        raise RuntimeError("Blender not available")

    tracking = clip.tracking

    # Create new track
    track = tracking.tracks.new(name=name or f"Track_{len(tracking.tracks)}")

    # Add marker at specified frame and position
    marker = track.markers.new_frame(frame)
    marker.co = position

    return track


def delete_track(clip, track_name: str) -> bool:
    """
    Delete a track by name.

    Args:
        clip: MovieClip containing the track
        track_name: Name of track to delete

    Returns:
        True if deleted, False if not found
    """
    if not BLENDER_AVAILABLE:
        raise RuntimeError("Blender not available")

    track = clip.tracking.tracks.get(track_name)
    if track:
        clip.tracking.tracks.remove(track)
        return True
    return False


def configure_track(
    track,
    motion_model: str = "Perspective",
    correlation_min: float = 0.6,
    pattern_match: str = "KEYFRAME",
    weight: float = 1.0,
    color: Optional[Tuple[float, float, float]] = None,
) -> None:
    """
    Configure track parameters for optimal tracking.

    Args:
        track: MovieTrackingTrack to configure
        motion_model: Motion model (LocRot, LocRotScale, Affine, Perspective)
        correlation_min: Minimum correlation threshold (0-1)
        pattern_match: KEYFRAME or PREV_FRAME
        weight: Track weight for solver (0-1)
        color: Optional RGB color for visualization (0-1 each channel)
    """
    track.motion_model = motion_model
    track.correlation_min = correlation_min
    track.pattern_match = pattern_match
    track.weight = weight

    if color:
        track.color = color
```

4. PointTracker Class:
```python
class PointTracker:
    """
    High-level point tracking workflow manager.

    Provides a simplified interface for complete tracking workflows.

    Usage:
        tracker = PointTracker(clip_path="footage/shot.mp4")
        tracker.detect_features(preset="balanced")
        tracker.track_all()
        tracker.clean_tracks()
        tracks = tracker.get_track_data()
    """

    def __init__(self, clip_path: str, preset: str = "balanced"):
        """Initialize tracker with footage and preset."""
        self.clip_path = clip_path
        self.clip = ensure_clip_loaded(clip_path)
        self.preset = preset

    def detect_features(self, **kwargs) -> int:
        """Detect features in current frame."""
        return detect_features(self.clip, preset=self.preset, **kwargs)

    def track_all(self, **kwargs) -> Dict[str, Any]:
        """Track all markers through clip."""
        return track_markers(self.clip, **kwargs)

    def clean_tracks(self, **kwargs) -> int:
        """Clean low-quality tracks."""
        return clean_low_quality_tracks(self.clip, **kwargs)

    def get_track_data(self) -> List[TrackData]:
        """Export tracks as TrackData objects."""
        result = []
        for track in self.clip.tracking.tracks:
            markers = {}
            for marker in track.markers:
                if not marker.mute:
                    markers[marker.frame] = tuple(marker.co)

            result.append(TrackData(
                name=track.name,
                markers=markers,
                enabled=not track.mute,
                color=tuple(track.color),
                correlation=track.correlation_min,
            ))
        return result
```

5. Include proper error handling and context management.
6. Follow patterns from the research document for Blender API usage.
</action>
  <verify>
python3 -c "
from lib.cinematic.tracking.point_tracker import (
    detect_features, track_markers,
    add_track, delete_track, configure_track,
    PointTracker, BLENDER_AVAILABLE
)

print(f'BLENDER_AVAILABLE: {BLENDER_AVAILABLE}')
print('Point tracker module imports work')

# Verify function signatures
import inspect
print(f'detect_features signature: {inspect.signature(detect_features)}')
print(f'track_markers signature: {inspect.signature(track_markers)}')
"
  </verify>
  <done>
- lib/cinematic/tracking/point_tracker.py created with full REQ-TRACK-POINT implementation
- detect_features() uses Blender's built-in detection
- track_markers() implements KLT optical flow via bpy.ops.clip.track_markers
- Track management functions (add, delete, configure) implemented
- PointTracker class provides high-level workflow
- All functions handle missing Blender gracefully
  </done>
</task>

<task type="auto">
  <name>Create track quality module</name>
  <files>lib/cinematic/tracking/quality.py</files>
  <action>
Create quality.py for track quality analysis and filtering.

Key implementation requirements:

1. Track Quality Analysis:
```python
def analyze_track_quality(clip) -> Dict[str, Any]:
    """
    Generate quality report for all tracks.

    Analyzes correlation, track length, and error metrics.

    Args:
        clip: MovieClip with tracks

    Returns:
        Dict with quality metrics:
        - total_tracks: Number of tracks
        - active_tracks: Number of enabled tracks
        - average_markers: Average markers per track
        - low_correlation_tracks: List of track names with low correlation
        - short_tracks: List of tracks with few markers
        - high_error_tracks: List of tracks with high average error
    """
    if not BLENDER_AVAILABLE:
        raise RuntimeError("Blender not available")

    report = {
        "total_tracks": len(clip.tracking.tracks),
        "active_tracks": 0,
        "average_markers": 0.0,
        "low_correlation_tracks": [],
        "short_tracks": [],
        "high_error_tracks": [],
    }

    total_markers = 0

    for track in clip.tracking.tracks:
        if track.mute:
            continue

        report["active_tracks"] += 1
        marker_count = len([m for m in track.markers if not m.mute])
        total_markers += marker_count

        # Check track length relative to clip duration
        clip_duration = clip.frame_duration
        if marker_count < clip_duration * 0.3:
            report["short_tracks"].append(track.name)

        # Check average error (if available)
        if hasattr(track, "average_error") and track.average_error > 2.0:
            report["high_error_tracks"].append({
                "name": track.name,
                "error": track.average_error,
            })

    if report["active_tracks"] > 0:
        report["average_markers"] = total_markers / report["active_tracks"]

    return report
```

2. Track Cleaning:
```python
def clean_low_quality_tracks(
    clip,
    frames: int = 5,
    error: float = 2.0,
    action: str = "DELETE",
) -> int:
    """
    Remove tracks with poor quality using Blender's clean_tracks operator.

    Args:
        clip: MovieClip with tracks
        frames: Remove tracks shorter than N frames
        error: Remove tracks with reprojection error > N pixels
        action: DELETE or DELETE_SEGMENTS

    Returns:
        Number of tracks removed
    """
    if not BLENDER_AVAILABLE:
        raise RuntimeError("Blender not available")

    track_count_before = len(clip.tracking.tracks)

    with tracking_context(clip) as ctx:
        bpy.ops.clip.clean_tracks(
            ctx,
            frames=frames,
            error=error,
            action=action,
        )

    return track_count_before - len(clip.tracking.tracks)


def filter_tracks_by_correlation(
    clip,
    min_correlation: float = 0.6,
) -> int:
    """
    Disable tracks below correlation threshold.

    Args:
        clip: MovieClip with tracks
        min_correlation: Minimum correlation threshold (0-1)

    Returns:
        Number of tracks disabled
    """
    if not BLENDER_AVAILABLE:
        raise RuntimeError("Blender not available")

    disabled_count = 0

    for track in clip.tracking.tracks:
        # Calculate average correlation across markers
        total_correlation = 0
        marker_count = 0

        for marker in track.markers:
            if not marker.mute:
                marker_count += 1
                # Note: marker.correlation may not be available in all Blender versions
                if hasattr(marker, "correlation"):
                    total_correlation += marker.correlation

        if marker_count > 0:
            avg_correlation = total_correlation / marker_count if total_correlation > 0 else track.correlation_min

            if avg_correlation < min_correlation:
                track.mute = True
                disabled_count += 1

    return disabled_count
```

3. Quality Report Generation:
```python
def get_track_quality_report(clip) -> str:
    """
    Generate human-readable quality report.

    Args:
        clip: MovieClip with tracks

    Returns:
        Formatted string report
    """
    data = analyze_track_quality(clip)

    lines = [
        "Track Quality Report",
        "=" * 40,
        f"Total Tracks: {data['total_tracks']}",
        f"Active Tracks: {data['active_tracks']}",
        f"Average Markers: {data['average_markers']:.1f}",
        "",
    ]

    if data["short_tracks"]:
        lines.append(f"Short Tracks ({len(data['short_tracks'])}):")
        for name in data["short_tracks"][:10]:
            lines.append(f"  - {name}")
        if len(data["short_tracks"]) > 10:
            lines.append(f"  ... and {len(data['short_tracks']) - 10} more")

    if data["high_error_tracks"]:
        lines.append(f"\nHigh Error Tracks ({len(data['high_error_tracks'])}):")
        for item in data["high_error_tracks"][:10]:
            lines.append(f"  - {item['name']}: {item['error']:.2f}px")

    return "\n".join(lines)
```

4. Include BLENDER_AVAILABLE checks and proper error handling.
</action>
  <verify>
python3 -c "
from lib.cinematic.tracking.quality import (
    analyze_track_quality, clean_low_quality_tracks,
    filter_tracks_by_correlation, get_track_quality_report,
    BLENDER_AVAILABLE
)

print(f'BLENDER_AVAILABLE: {BLENDER_AVAILABLE}')
print('Quality module imports work')

# Verify function signatures
import inspect
print(f'analyze_track_quality signature: {inspect.signature(analyze_track_quality)}')
print(f'get_track_quality_report signature: {inspect.signature(get_track_quality_report)}')
"
  </verify>
  <done>
- lib/cinematic/tracking/quality.py created with track quality analysis
- analyze_track_quality() provides comprehensive metrics
- clean_low_quality_tracks() uses bpy.ops.clip.clean_tracks
- filter_tracks_by_correlation() disables low-correlation tracks
- get_track_quality_report() generates human-readable output
  </done>
</task>

</tasks>

<verification>
# Phase-level verification
1. point_tracker.py imports without errors
2. quality.py imports without errors
3. All tracking functions have proper context management
4. Functions handle missing Blender gracefully
5. Function signatures match research recommendations
</verification>

<success_criteria>
- lib/cinematic/tracking/point_tracker.py implements REQ-TRACK-POINT
- lib/cinematic/tracking/quality.py provides track quality analysis
- Feature detection uses Blender's built-in API
- KLT optical flow tracking via bpy.ops.clip.track_markers
- Track management (add, delete, configure) working
- Quality analysis identifies problematic tracks
</success_criteria>

<output>
After completion, create `.planning/phases/07.1-core-tracking/07.1-02-SUMMARY.md`
</output>
